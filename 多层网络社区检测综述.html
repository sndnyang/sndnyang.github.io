<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title></title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="http://cdn.bootcss.com/reveal.js/3.2.0/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="http://cdn.bootcss.com/reveal.js/3.2.0/css/theme/black.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'http://cdn.bootcss.com/reveal.js/3.2.0/css/print/pdf.css' : 'http://cdn.bootcss.com/reveal.js/3.2.0/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="http://cdn.bootcss.com/reveal.js/3.2.0/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">


<section class="slide level2">

<p>Title: 多层网络聚落检测综述<br />
Date: 2016-3-14<br />
Author: sndnyang<br />
Slug: multi_layer_cd_suver<br />
Category: 研究<br />
tags: 论文, 多目标进化算法, 群落检测</p>
<p>[TOC]</p>
</section>
<section id="摘要" class="slide level2">
<h1>摘要</h1>
<p>Community Detection in Multi-Layer Graphs: A Survey</p>
<p>本文介绍多层网络下聚落检测问题， 并对相应算法做综述</p>
</section>
<section id="导论---过" class="slide level2">
<h1>导论 - 过</h1>
</section>
<section><section id="背景知识" class="titleslide slide level1"><h1>背景知识</h1></section><section id="群落社区-community" class="slide level2">
<h1>群落/社区 community</h1>
<ol type="1">
<li>densely-connected components/subgraph</li>
<li>relative/similar</li>
</ol>
<p>比如：</p>
<ol type="1">
<li>同校、 同系、 同班是一个 community</li>
<li>同一个社团、 公司</li>
<li>同一领域的研究</li>
</ol>
</section><section id="多层网络模型" class="slide level2">
<h1>多层网络模型</h1>
<p>关系的不同方面就可以表达成多个独立图组成的多层图， 里面的每个、每层图就代表了一个方面</p>
<p>比如：</p>
<ol type="1">
<li>同学关系</li>
<li>微信好友</li>
<li>微博好友</li>
</ol>
</section><section id="单层图定义" class="slide level2">
<h1>单层图定义</h1>
<ol type="1">
<li>a weighted graph (V,w)</li>
<li>V is a set of vertices</li>
<li>w is a set of edge weights: (V × V ) → [0,1].</li>
</ol>
</section><section id="点映射图层之间" class="slide level2">
<h1>点映射(图层之间)</h1>
<ol type="1">
<li>node mapping is a function</li>
<li>from a graph layer L1 = (V1 ,w1 ) to another graph layer L2 = (V2 ,w2 )</li>
<li>V1 × V2 → [0,1].</li>
<li>For each u ∈ V 1 , the set C(u) = {v ∈ V2 |f(u,v) &gt; 0} is the set of V2 vertices corresponding to u.</li>
</ol>
<p>对于一个facebook上的账号（个人）：</p>
<ol type="1">
<li>twitter 上没有账号</li>
<li>twitter 上只有一个号--pillar(柱型) multi-layer graph</li>
<li>twitter 上多个号</li>
</ol>
</section><section id="多层图定义" class="slide level2">
<h1>多层图定义</h1>
<ol type="1">
<li>a tuple MLN = (L1 ,...,Ll ,IM)</li>
<li>where Li = (Vi ,wi ),i ∈ 1,...,l are graph layers</li>
<li>IM (Identity Mapping) is an l ×l matrix of node mappings, with $ IM_{i,j} : V_i ×V_j → [0,1] $</li>
</ol>
<p>例：</p>
<ol type="1">
<li>症状</li>
<li>疾病名</li>
<li>细菌、病毒或基因</li>
</ol>
</section><section id="信息网络定义" class="slide level2">
<h1>信息网络定义：</h1>
<ol type="1">
<li>是个有向图，</li>
<li>存在“点”到“点类别” 的函数映射</li>
<li>及 “边”到“关系(边)类别”的函数映射</li>
</ol>
</section><section id="异构信息网络" class="slide level2">
<h1>异构信息网络</h1>
<p>Heterogeneous Information Networks</p>
<p>点的类别 或 关系的类别个数大于1的信息网络。</p>
</section><section class="slide level2">

<p><strong>异构信息网络与多层网络模型 等价</strong></p>
<p>但强调不太相同</p>
<p>heterogeneous information networks emphasize heterogeneous types of entities connected by different relationships</p>
</section></section>
<section><section id="主要方法" class="titleslide slide level1"><h1>主要方法</h1></section><section id="分类" class="slide level2">
<h1>分类</h1>
<ol type="1">
<li>聚类扩展 cluster expansion</li>
<li>矩阵分解 matrix factorization</li>
<li>统一距离？ unified distance</li>
<li>基于概率模型 model based</li>
<li>模式挖掘 pattern mining</li>
<li>图合并 graph merging</li>
</ol>
</section><section id="特点" class="slide level2">
<h1>特点</h1>
<ol type="1">
<li>多数只支持两层图</li>
<li>一层是图的原始拓扑结构信息</li>
<li>其他层一般是利用点的属性信息来计算相似度</li>
</ol>
</section></section>
<section><section id="聚类扩展" class="titleslide slide level1"><h1>聚类扩展</h1></section><section id="cluster-expansion" class="slide level2">
<h1>Cluster Expansion</h1>
<p>论文： Scalable community discovery on textual data with relations</p>
<p>基于关系（文章引用）与文本属性</p>
</section><section id="针对的问题" class="slide level2">
<h1>针对的问题</h1>
<p>大型文档语料 -- large cocument corpus</p>
<ol type="1">
<li>没有同时考虑 textual attribute 和 relations(文献里的引用？)</li>
<li>大数据集的可扩展性scalability</li>
<li>多数算法基于一堆要（人工）设定的参数</li>
</ol>
</section><section id="思路" class="slide level2">
<h1>思路</h1>
<p>非监督方法</p>
<ol type="1">
<li>快速地找到初始的核， 作为群落的种子</li>
<li>核进行扩展（或合并merge)， 扩展成群落，（提高scalability)</li>
</ol>
<p>cores dictate the formation and topics of communities</p>
<p>核 用来表示 社区的构造和主题</p>
</section><section id="步骤" class="slide level2">
<h1>步骤</h1>
<p>4 steps:</p>
<ol type="1">
<li>core probing</li>
<li>core merging, 根据主题相似度进行合并</li>
<li>affiliation, 利用关系信息，将core扩展成初始社区</li>
<li>classification， 主题不相关的成员从社区中移除</li>
</ol>
</section><section id="第一步-core-probing" class="slide level2">
<h1>第一步 Core Probing</h1>
<h3 id="基本思想">基本思想</h3>
<p>co-occurrence analysis: multiple objects are linked simultaneously by others, they are more likely to be able to define a coherent topic scope</p>
</section><section class="slide level2">

<h3 id="prob-步骤">prob 步骤</h3>
<ol type="1">
<li>生成每个点的outgoing relations</li>
<li>用关联规则来计算频繁项集(Apriori)</li>
</ol>
<figure>
<img src="img/cikm2008_original.png" alt="original" /><figcaption>original</figcaption>
</figure>
</section><section class="slide level2">

<h3 id="与-apriori-的不同点">与 Apriori 的不同点</h3>
<ol type="1">
<li>不使用固定的过滤阈值， 根据项集的长度决定阈值</li>
<li>项集存在包含关系，如果项集 S1 和 S2存在 $ S1 S2 $, 不保留S1</li>
</ol>
</section><section id="core-merging" class="slide level2">
<h1>core merging</h1>
<p>保证了合并后核的高度一致性， 不受过滤阈值的影响</p>
<p>证明过程略</p>
</section><section class="slide level2">

<h3 id="步骤-1">步骤</h3>
<p>输入参数: core probing 返回的核</p>
<p>迭代：</p>
<ol type="1">
<li>对S中任意一对核Ki, Kj， 如果重叠， 转2</li>
<li>计算p-min, p-max, p-</li>
<li>如果 Ki, Kj的交集不为空，且 pi- 或 pj- 属于 该交集， 转4</li>
<li>从S 中移除Ki, 和 Kj, 加入Ki,Kj的并集。</li>
<li>如果遍历完， S 没有变化， 则退出</li>
</ol>
</section><section class="slide level2">

<h3 id="计算-p-min-p-max-p-">计算 p-min, p-max, p-</h3>
<figure>
<img src="img/cikm2008_pvalue.png" alt="pvalue" /><figcaption>pvalue</figcaption>
</figure>
<ol type="1">
<li>p-min, pmax: 在特征空间内， 为 core生成了边界框</li>
<li>p- : 中心</li>
</ol>
</section><section class="slide level2">

<h3 id="图示">图示：</h3>
<figure>
<img src="img/cikm2008_merge_view.png" alt="merge-view" /><figcaption>merge-view</figcaption>
</figure>
</section><section id="affiliation-propagation" class="slide level2">
<h1>Affiliation Propagation</h1>
<p>完成cores probe后，剩余的点作为 affiliated members</p>
<p>初始化社区C = 找到的核K ， 迭代处理：</p>
<ol type="1">
<li>对K中的每个点d，把所有的、其他的、能连到d的点u 加到C中</li>
<li>设定迭代次数， 避免关系环</li>
<li>或迭代中 没有新的点加入</li>
</ol>
</section><section class="slide level2">

<h3 id="相关概念">相关概念</h3>
<p>好像没什么用</p>
<ol type="1">
<li>两个社区的公共成员则为 interdisciplinary member</li>
<li>点和社区间的相近度(closeness)用迭代时的次数代表</li>
</ol>
</section><section id="intra-community-classification" class="slide level2">
<h1>Intra-Community Classification</h1>
<p>只根据relation找到的社区 很可能误判(false hits)</p>
<p>要根据属性分析， 将当前的C 划分成两个集合， C' 和 C-</p>
</section><section class="slide level2">

<h3 id="步骤-2">步骤</h3>
<ol type="1">
<li>核K 视作是 positive example正例， 即肯定属于这个社区</li>
<li>选择社区C的核K（正例） 和 其他社区的核（negative example)</li>
<li>将所有点转换成 特征向量（feature vector）来代表它们的topical position</li>
<li>使用 LDA（Latent Dirichlet Allocation）来降维</li>
<li>使用某种分类器（SVM），将负标签的点都移除</li>
</ol>
</section><section id="图示-1" class="slide level2">
<h1>图示</h1>
<p><img src="img/cikm2008_original.png" alt="original" /> <img src="img/cikm2008_probing.png" alt="prob" /></p>
</section><section class="slide level2">

<p><img src="img/cikm2008_merge.png" alt="merge" /> <img src="img/cikm2008_affiliation.png" alt="affiliation" /> <img src="img/cikm2008_classification.png" alt="classification" /></p>
</section><section id="主要贡献" class="slide level2">
<h1>主要贡献</h1>
<ol type="1">
<li>用关联规则、频繁项集来初始化</li>
</ol>
</section></section>
<section><section id="统一距离" class="titleslide slide level1"><h1>统一距离</h1></section><section id="unified-distance" class="slide level2">
<h1>Unified Distance</h1>
<p>structural and attribute similarities using a unified distance measure</p>
<p>SA-Cluster</p>
</section><section id="步骤-3" class="slide level2">
<h1>步骤</h1>
<ol type="1">
<li>建立统一距离度量， 新的图</li>
<li>用新的图 进行聚类， 类k-means</li>
</ol>
</section><section class="slide level2">

<h3 id="unified-distance-measure">unified distance measure</h3>
<p>基于属性增广图(attribute-argmented graph), 使用Random Walk with Restart (RWR)</p>
</section><section class="slide level2">

<h4 id="邻点随机游走距离-neighborhood-random-walk-distance">邻点随机游走距离 Neighborhood Random Walk Distance</h4>
<figure>
<img src="img/28-rwd.png" alt="rwd" /><figcaption>rwd</figcaption>
</figure>
<ol type="1">
<li>l as the length that a random walk can go</li>
<li>c ∈ (0, 1) as the restart probability</li>
</ol>
</section><section class="slide level2">

<h4 id="attribute-argmented-graph">attribute-argmented graph</h4>
<ol type="1">
<li>添加属性点（attribute vertices），代表属性的值。</li>
<li>原始的点连接到对应的属性点上</li>
<li>两点上共同的属性点越多， 两点相似度直觉上就越高。</li>
</ol>
<figure>
<img src="img/28-augmented-graph.png" alt="augment graph" /><figcaption>augment graph</figcaption>
</figure>
</section><section id="聚类算法" class="slide level2">
<h1>聚类算法</h1>
<p>利用unified distance measure， 进行 k-medoids clustering（类似 k-means）</p>
<ol type="1">
<li>选择每个聚簇(cluster)最中心的点</li>
<li>其余点分配给最近的中心点。</li>
<li>迭代， 调整边的权重</li>
</ol>
</section><section id="聚类中心初始化" class="slide level2">
<h1>聚类中心初始化</h1>
<p>思想： 从vi走 l 步能到的点越多， vi越可能是中心</p>
<ol type="1">
<li>计算点的密度函数： <img src="img/28-density-function.png" alt="density" /></li>
<li>降序排列， 选择前k点作为聚类中心</li>
</ol>
</section><section id="聚类过程" class="slide level2">
<h1>聚类过程</h1>
<ol type="1">
<li>分配点到最近的中心，即有最大random walk distance的中心点</li>
<li>对每个cluster ,用随机游走距离 计算“平均点”</li>
<li>寻找新的中心点，距“平均点”最近</li>
<li>不停迭代， 直到 聚类目标函数 收敛</li>
</ol>
</section><section id="聚类目标函数" class="slide level2">
<h1>聚类目标函数</h1>
<p>目标是最大化</p>
<figure>
<img src="img/28-objective-function.png" alt="obj function" /><figcaption>obj function</figcaption>
</figure>
<figure>
<img src="img/28-set-distance.png" alt="set distance" /><figcaption>set distance</figcaption>
</figure>
</section><section class="slide level2">

<h3 id="问题转化">问题转化</h3>
<p>有以上的目标函数后， 可转化成三个子问题</p>
<ol type="1">
<li>聚类分配</li>
<li>中心更新</li>
<li>权重调整</li>
</ol>
</section><section id="权重自我调整" class="slide level2">
<h1>权重自我调整</h1>
<p>在每次迭代时， 进行权重调整</p>
<p>属性 ai 权重在第t+1次迭代的计算公式为：</p>
<figure>
<img src="img/28-weight-adjust.png" alt="weight-adjust" /><figcaption>weight-adjust</figcaption>
</figure>
<figure>
<img src="img/28-delta-weight.png" alt="delta-weight" /><figcaption>delta-weight</figcaption>
</figure>
</section><section class="slide level2">

<h3 id="投票机制-majority-voting-mechanism">投票机制 majority voting mechanism</h3>
<p>counts the number of vertices within clusters that share the same attribute values with the centroids on ai</p>
<figure>
<img src="img/28-voting.png" alt="voting" /><figcaption>voting</figcaption>
</figure>
</section><section id="主要贡献-1" class="slide level2">
<h1>主要贡献</h1>
<ol type="1">
<li>一个统一的距离评估方式， 将结构和属性相似度结合</li>
<li>带权重的自调整方法， 调节结构属性相似度的重要度</li>
</ol>
</section></section>
<section><section id="基于模型方法" class="titleslide slide level1"><h1>基于模型方法</h1></section><section id="model-based-method" class="slide level2">
<h1>Model-Based Method</h1>
<p>model-based community detection approach based on both structural and attribute aspects of a graph</p>
</section><section id="步骤关键点" class="slide level2">
<h1>步骤关键点</h1>
<ol type="1">
<li>概率模型的构建， 结合结构和属性信息， 不使用人工定义的距离</li>
<li>变分法(variational approach)解决模型</li>
</ol>
</section><section id="构建概率模型" class="slide level2">
<h1>构建概率模型</h1>
<p>聚类属性图定义：</p>
<ol type="1">
<li>X: n x n 的邻接矩阵</li>
<li>Y: n x t 的属性矩阵</li>
<li>Z: n x 1 的聚类向量， 即每个点所属的聚类</li>
</ol>
</section><section id="目标" class="slide level2">
<h1>目标：</h1>
<p>求最优化：<img src="img/26-map.png" alt="map" /></p>
<p>其中</p>
<figure>
<img src="img/26-posterior.png" alt="posterior" /><figcaption>posterior</figcaption>
</figure>
</section><section class="slide level2">

<p>联合概率分布</p>
<figure>
<img src="img/26-joint-prob.png" alt="joint-prob" /><figcaption>joint-prob</figcaption>
</figure>
<ol type="1">
<li>alpha - 每个聚类的点分布（vertex distribution)</li>
<li>theta - 属性分布(attribute distribution)</li>
<li>phi - 类间 边出现概率(edge occurrence prob)</li>
</ol>
</section><section id="两大问题" class="slide level2">
<h1>两大问题</h1>
<ol type="1">
<li>Z 的N个变量最大化 计算量过大， 全局最优基本不可能</li>
<li>计算Z的后验概率分布时， 不存在 p(Z|X,Y)的closed-form expression</li>
</ol>
</section><section id="变分法-variational-algorithm" class="slide level2">
<h1>变分法 variational algorithm</h1>
<p>使用variational distribution q(α, θ, φ, Z) 来逼近原分布</p>
<p>并且对 variational distribution 作限制</p>
<figure>
<img src="img/26-var-distri.png" alt="var-distri" /><figcaption>var-distri</figcaption>
</figure>
</section><section class="slide level2">

<p>全局最优就转成求局部最优</p>
<figure>
<img src="img/26-local-maximum.png" alt="local-max" /><figcaption>local-max</figcaption>
</figure>
</section><section id="两个新问题" class="slide level2">
<h1>两个新问题</h1>
<ol type="1">
<li>如何定义the family of variational distributions</li>
<li>如何从中找出最优分布， 最接近p(α, θ, φ, Z|X, Y)</li>
</ol>
</section><section class="slide level2">

<h3 id="parametric-family">Parametric Family</h3>
<figure>
<img src="img/26-map-simple.png" alt="map-simple" /><figcaption>map-simple</figcaption>
</figure>
</section><section class="slide level2">

<h3 id="optimizing-variational-parameters">Optimizing Variational Parameters</h3>
<p>measure the distance between a variational distribution q(α, θ, φ, Z) and the true posterior p(α, θ, φ, Z|X, Y)</p>
<figure>
<img src="img/26-kl-divergence.png" alt="kl-divergence" /><figcaption>kl-divergence</figcaption>
</figure>
</section><section class="slide level2">

<p>等价于 最大化</p>
<figure>
<img src="img/26-kl-maxim.png" alt="kl-maxim" /><figcaption>kl-maxim</figcaption>
</figure>
<p>关系式：</p>
<figure>
<img src="img/26-kl-relate.png" alt="kl-relate" /><figcaption>kl-relate</figcaption>
</figure>
</section></section>
<section><section id="图合并" class="titleslide slide level1"><h1>图合并</h1></section><section id="graph-merging" class="slide level2">
<h1>Graph Merging</h1>
<p>combine structural and attribute information using the graph merging process</p>
<p>CODICIL</p>
</section><section id="步骤-4" class="slide level2">
<h1>步骤</h1>
<ol type="1">
<li>创建内容边 create content edges</li>
<li>边组合 combining edges</li>
<li>边采样 sampling edges with bias</li>
<li>聚类 clustering</li>
</ol>
</section><section class="slide level2">

<h3 id="creating-content-edges">creating content edges</h3>
<ol type="1">
<li>对每个点vi, 用cosine相似度， 计算k 内容最近邻</li>
<li>在vi 和 k近邻间 建立content edges</li>
</ol>
</section><section class="slide level2">

<h3 id="combining-edges">combining edges</h3>
<p>将新创建的content edges 和 初始的拓扑边集进行简单的联合(unified)</p>
</section><section class="slide level2">

<h3 id="sampling-edges-with-bias">sampling edges with bias</h3>
<p>对每个点 vi， 从邻点选择要保留的边， 通过 cosine 相似度或Jaccard 相似度</p>
</section><section class="slide level2">

<h4 id="clustering">clustering</h4>
<p>因为图合并部分独立于community detection， 所以任意 community detection 都可以，</p>
<p>这块不是本文的重点</p>
</section><section id="主要贡献-2" class="slide level2">
<h1>主要贡献</h1>
<p>通过 用内容信息消除连接结构里的噪音， 来强化社区信号</p>
</section></section>
<section><section id="矩阵分解" class="titleslide slide level1"><h1>矩阵分解</h1></section><section id="matrix-factorization" class="slide level2">
<h1>Matrix Factorization</h1>
<p>论文： Community Detection with Edge Content in Social Media Networks</p>
<p>Edge-Induced Matrix Factorization</p>
</section><section id="主要idea" class="slide level2">
<h1>主要idea</h1>
<ol type="1">
<li>通过从多层图中抽取相同因子(common factors)</li>
<li>把不同信息进行结合</li>
<li>使用通用的聚类方法处理</li>
</ol>
</section><section id="方法" class="slide level2">
<h1>方法</h1>
<ol type="1">
<li>使用 低秩矩阵因子分解(low-rank matrix factorization) 来逼近目标矩阵O， <img src="img/25-matrix-factors.png" alt="o=PAP&#39;" /></li>
<li>P: n x n 的特征矩阵</li>
<li>lambda(大写的？): n x n 特征值矩阵</li>
</ol>
</section><section id="目标-1" class="slide level2">
<h1>目标</h1>
<p>对于多个目标矩阵O^i, i = 1,-,l</p>
<p>要算出一个common factor matrix</p>
</section><section class="slide level2">

<h3 id="求最小化">求最小化：</h3>
<figure>
<img src="img/25-obj-minimize.png" alt="obj-mini" /><figcaption>obj-mini</figcaption>
</figure>
<ol type="1">
<li>P: n x n的所有层 公因子矩阵</li>
<li>Λ^i: n x n 矩阵， 第i层的特征</li>
<li>|| ·|| is the Frobenius norm</li>
<li>α: regularization 参数</li>
</ol>
</section><section id="全局转局部最优" class="slide level2">
<h1>全局转局部最优</h1>
<p>迭代处理：</p>
<ol type="1">
<li>固定P , 优化 Λ^i</li>
<li>固定Λ^i , 优化 P</li>
<li>直到 收敛</li>
</ol>
</section></section>
<section><section id="模式挖掘" class="titleslide slide level1"><h1>模式挖掘</h1></section><section id="pattern-mining" class="slide level2">
<h1>Pattern Mining</h1>
<p>Coherent Closed Quasi-Clique Discovery from Large Dense Graph Databases</p>
<p>Cocain</p>
</section><section id="方法-1" class="slide level2">
<h1>方法</h1>
<p>子图挖掘算法， 搜索多层图中频率高于某给定阈值的 quasi-cliques</p>
</section><section id="基础定义" class="slide level2">
<h1>基础定义</h1>
<figure>
<img src="img/27-pattern-mining-notation.png" alt="formation" /><figcaption>formation</figcaption>
</figure>
</section><section class="slide level2">

<h4 id="gammaγ-quasi-clique">gamma(γ)-Quasi-clique</h4>
<figure>
<img src="img/quasi-clique.png" alt="Quasi-clique" /><figcaption>Quasi-clique</figcaption>
</figure>
</section><section class="slide level2">

<h4 id="cross-graph-quasi-clique">cross-graph quasi-clique:</h4>
<p>a set of vertices</p>
<ol type="1">
<li>belonging to a quasi-clique</li>
<li>appears on all layers</li>
<li>must be the maximal set</li>
</ol>
</section><section class="slide level2">

<h4 id="edge-cut-edge-connectivity">Edge Cut, Edge Connectivity</h4>
<ol type="1">
<li>edge cut is a set of edges Ec such that G'=(V ,E-Ec) is disconnected</li>
<li>A minimum cut is the smallest set among all edge cuts.</li>
<li>The edge connectivity of G, denoted by κ(G), is the size of the minimum cut</li>
</ol>
<p>coherent subgraph: a subgraph that satisfies a minimum cut bound</p>
</section><section class="slide level2">

<h4 id="gammaγ-isomorphism-同构">gamma(γ)-Isomorphism 同构</h4>
<p>若两个图G1, G2是 gamma同构， 当且仅当：</p>
<ol type="1">
<li>都是 γgamma-quasi-cliques</li>
<li>点个数相同</li>
<li>存在 biject f:V1-&gt;V2, 对V1中的每个点v, 满足F1(v) = F2(f(v))</li>
</ol>
</section><section class="slide level2">

<h4 id="multiset">multiset</h4>
<ol type="1">
<li>点的标签的集合(a bag of vertex labels)</li>
<li>忽略顺序</li>
<li>突出多样性</li>
<li>定义为 M(G)， G的multiset</li>
</ol>
</section><section class="slide level2">

<h4 id="string-of-a-graph">string of a graph</h4>
<p>Given a k-graph g, any sequence of all elements in M(g)</p>
<p>给定 k-graph g, M(g)的任意一种序列</p>
</section><section class="slide level2">

<h4 id="canonical-form-of-a-graph">canonical form of a graph</h4>
<p>the minimum string among all its strings and denoted by CF(G)</p>
<p>图的最小 string, 记作 CF(G)</p>
<p>有引理：</p>
<p>两个γ-quasi-cliques Q1 Q2 是γ同构， 当且仅当 CF(Q1) = CF(Q2)</p>
</section><section id="步骤-5" class="slide level2">
<h1>步骤</h1>
<ol type="1">
<li>将子图转成 canonical forms</li>
<li>枚举γ-quasi-cliques可行解(feasible candidate for γ-quasi-cliques), 用DFS策略进行剪枝</li>
<li>基于 闭包检查规划(closure-checking scheme)， 选择出闭包的 γ-quasi-cliques</li>
</ol>
</section><section class="slide level2">

<h3 id="枚举策略">枚举策略</h3>
<ol type="1">
<li>枚举树</li>
<li>满足： 子代必须能归入祖先</li>
</ol>
<p>关键：</p>
<p>对每个 quasi-clique Q, 处理完它的子代后， 进行闭包检查</p>
</section><section id="主要贡献-3" class="slide level2">
<h1>主要贡献</h1>
<p>find cross-graph quasi-cliques in a multi-layer graph that are frequent, coherent, and closed</p>
</section></section>
<section><section id="另一篇模式挖掘" class="titleslide slide level1"><h1>另一篇模式挖掘</h1></section><section id="论文" class="slide level2">
<h1>论文</h1>
<p>论文： Mining Coherent Subgraphs in Multi-Layer Graphs with Edge Labels</p>
</section><section id="本文贡献" class="slide level2">
<h1>本文贡献</h1>
<ol type="1">
<li>提出了带边标签的多层图聚类的新范式</li>
<li>提出了MLCS, 避免了结果集的冗余</li>
<li>提出了最好优先搜索算法MiMAG 来求MLCS聚类的近似解</li>
</ol>
</section><section class="slide level2">

<h3 id="multi-layer-coherent-subgraph-mlcs-model">multi-layer coherent subgraph (MLCS) model</h3>
<p>clusters of vertices that are densely connected by edges with similar labels in a subset of the graph layers</p>
<p>找聚类， 满足条件：在某层的图中，不仅边的密度高，且具有相似的标签。</p>
<p>the edge labels represent characteristics of the relations</p>
</section><section id="quasi-clique" class="slide level2">
<h1>quasi-clique</h1>
<p>One-dimensional MLCS cluster</p>
</section><section id="one-dimensional-mlcs-cluster" class="slide level2">
<h1>One-dimensional MLCS cluster</h1>
<p>某一图（层）的点集满足以下条件：</p>
<ol type="1">
<li>形成一个 0.5-quasi-clique</li>
<li>点集的每条边的两个顶点： dist(l_i(x), l_i(y)) &lt;= w, edge label 为连续值时需要w, 不然置为0.</li>
</ol>
</section><section id="多层-mlcs-cluster" class="slide level2">
<h1>多层 MLCS cluster</h1>
</section><section id="冗余关系-redundancey-relation" class="slide level2">
<h1>冗余关系 redundancey relation</h1>
</section><section id="mimag-算法" class="slide level2">
<h1>MiMAG 算法</h1>
<p>Mining Multi-layered, Attributed Graphs</p>
<p>计算出最大化、 无冗余、 高质量（不是最优质量）的聚类</p>
<p>基于寻找quasi-cliques的快速算法。</p>
</section></section>
<section><section id="总结" class="titleslide slide level1"><h1>总结</h1></section><section id="section" class="slide level2">
<h1></h1>
<ol type="1">
<li>Apriori 频繁项集的， 特例或通用</li>
<li>随机游走</li>
<li>概率模型</li>
<li>矩阵分解</li>
<li>clique</li>
</ol>
<p>community 没有严格定义</p>
</section></section>
<section><section id="未来研究方向" class="titleslide slide level1"><h1>未来研究方向</h1></section><section id="通用多层图的适应性" class="slide level2">
<h1>通用多层图的适应性</h1>
<p>General multi-layer graph applicability</p>
<p>当前算法一般仅研究了 pillar(柱形)多层图</p>
<p>现实世界不保证不同层之间正好一一对应</p>
<p>所以现有算法的泛化， 对通用多层图的适应性非常有意义</p>
</section><section id="多层图的不确定性" class="slide level2">
<h1>多层图的不确定性</h1>
<p>Uncertainty in multi-layer graphs</p>
<p>现有的研究都假定 图数据已经清理完毕， 缺少噪音、歧义的研究</p>
<p>constructing multi-layer graphs with entity resolution and/or trustworthy analysis certainly enhances the quality of the community detection process</p>
</section><section id="可扩展性问题" class="slide level2">
<h1>可扩展性问题</h1>
<p>所以可能要考虑并行及分布式之类的方法</p>
<p>或是对多层图的特征向量矩阵（feature-vector matrices）进行采样</p>
</section><section id="temporal-analysis" class="slide level2">
<h1>Temporal analysis</h1>
<p>图是随时间变化的。</p>
<p>目前存在一些对单层图的时间变化的研究， 但基本不可用于多层图</p>
</section></section>
<section><section id="谢谢" class="titleslide slide level1"><h1>谢谢！</h1></section></section>
    </div>
  </div>

  <script src="http://cdn.bootcss.com/reveal.js/3.2.0/lib/js/head.min.js"></script>
  <script src="http://cdn.bootcss.com/reveal.js/3.2.0/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({

        // Optional reveal.js plugins
        dependencies: [
          { src: 'http://cdn.bootcss.com/reveal.js/3.2.0/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'http://cdn.bootcss.com/reveal.js/3.2.0/plugin/zoom-js/zoom.js', async: true },
          { src: 'http://cdn.bootcss.com/reveal.js/3.2.0/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
