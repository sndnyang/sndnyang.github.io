{"pages":[{"url":"sndnyang.github.io/zhimind-datastruct.html","text":"数据结构可视化 DataStructVis.js--基于vis.js制作的基本数据结构可视化库（散点图基于 echarts.js） 使用说明 全局变量满足， 见下面全局变量说明 选择div容器 -- var container = document.getElementById('datastruct'); 选择数据结构类型 -- 见后面列表 创建 variable = type(container, size) 如structure = LinkedList(container, 10); 全局变量说明 一开始没有进行分析设计， 还在使用多个全局变量， 没有设置成内部变量， 全局变量分别是： nodes nodeSet edges edgeSet data network 支持数据结构 示例见（不建议在这个网页上改大的数值--起码有向图挺卡的）： demo 链表 栈 队列 森林 -- 允许多棵树 树 -- 单棵树，分支不限 二叉树 -- 分支限制不超过2 左右子树目前不能确定， 只能用 空结点（无标签）来设定。 无向图 有向图 -- 目前暂不支持在自动生成图时 设定密度 矩阵 散列表 散点图（2D） 高级数据结构基本可显示成以上结构， 所以感觉不需要。 功能列表 随机初始化 -- 都有简单版本 解析数据 -- 都可解析对应格式数据， 并重新绘制 链表： 列表数据， 如 [1,2,3] 栈： 列表数据 队列： 列表数据 森林： json数据， 不能有环， 如 {1: [2,3,4], 2: [5], 3: [6], 7} 树： json数据， 只能有一个根。 二叉树： json数据， 子结点不能超过2个。 有向图： json数据 无向图： json数据 矩阵： 二维数组数据 散列表: json数据 散点图：二维点列表， 如： [点1, 点2, 点3]， 点格式： [[x], y, class], [x]本来是为了支持3维--TODO：改掉 更新数据 -- 少量有实现自己的更新数据接口： 链表: add 标签， swap 交换标签， remove 值， removeID 移除ID 栈： pop, push 队列： enqueue, dequeue 点标记 -- markNodes([id1, id2, id3, idn]), 将相应id的点修改成红色。 交换标签 -- 待全部实现 setData -- 数据重绘， 数据格式自定义","tags":"zhimind","title":"zhimind-数据结构可视化"},{"url":"sndnyang.github.io/zhimind-practice-manual.html","text":"练习使用说明 文本部分同 教程说明 zhimind教程 需要在和文本文件同一路径下有一个 answer.js 文件 answer.js定义 定义函数 initData(): 自定义界面样式， 并为某div 创建可视数据结构， 见 datastructvis 定义 procedure(v): v 是数据， 定义算法过程生成的 stepLog 列表。","tags":"zhimind","title":"zhimind练习开发"},{"url":"sndnyang.github.io/zhimind-manual.html","text":"思维导图使用步骤 注册登录 个人主页点创建新思维导图 或 首页直接点新导图 编辑导图（存在bug， 未解决） 鼠标在点上悬停时， 会显示四个小图标（有bug,可能被另一个tooltip挡住）， 分别为： 插入子结点 删除当前结点 修改结点名称 添加新属性（即外链） 快捷键方法。 鼠标选中一点后 快捷键insert插入子结点 enter 插入同级结点（根结点不能enter） delete 删除该结点 存档。 未注册不能保存云上， 仍可以导出 json 格式文件。 查找他人的导图。 点击导航栏上的 列表。 在思维导图列表下点击一个打开导图（目前只有几个）， 点击存档可直接保存。可到个人主页查看。 教程和练习使用说明 在列表页， 查找目前存在的教程和练习。可直接打开。 关联到导图。 给导图结点添加新属性。 属性名填写练习或教程。 链接输入原页面的链接。 新建教程和练习 在个人主页点击， 输入 文本文件的链接（暂不支持平台新建，全部从外部读）， 后缀必须是 .mkd 或 .md 或在导图上添加属性时， 属性名填写 练习或教程， 链接输入文本文件的链接， 后缀必须是 .mkd 或 .md。 文件格式 主体部分与markdown 一致 新加题目格式(写成一行)： {%type |可填题干 &a&b&c 选择题的选项 @a@b答案，多选题和多空格的答案用@分开 #提示1#提示2] %} 示例 {%radio|请选择&a&b&c&d@d#随便%} 单选 {%checkbox|请选择&a&b&c&d@d#随便%} 多选 {%text|请填空:_是有意义的,_也是有意义的@教育@数学#随便写点什么#不想写也可以%} 填空 {%formula|请填空:公式_@(1+6*x&#94;3*x&#94;2)/(2+5*x&#94;4)+9#随便%} 公式填空 其他说明 填空和公式题 题干必填 ， 用 _ 代表一个空 填空使用关键字查找方式， 多关键字用普通空格（非全角）隔开——其他符号中文输入法和英文经常不一样。 示例： {%text|请填空:_是有意义的,_也是有意义的@教育 科学@数学 物理 化学#随便写点什么#不想写也可以%} 水平有限， 关键字顺序不论 感想 目标是能智能地批改 数学、 物理等客观题作业， 并智能地给以思路提示。 但还没有想法。 选择题简单， 但提示不智能——选择题还算好了。 填空题难准确。提示也很死。 公式比较都比较困难， sympy 的 simplify_logic 凑合用， 但只认普通函数， 线性代数或方程, 如 $ w&#94;Tx+b=0 $， 带 = 号， 线性代数转置 &#94;T 都不对。 理想境界 就是对多步的计算题 和 证明题进行智能批改、 提示。","tags":"zhimind","title":"zhimind使用说明"},{"url":"sndnyang.github.io/total-probability.html","text":"问题引入 已知色盲基因由X染色体携带，且若男性的X染色体有此基因则 男性患色盲，女性则要两个X染色体均有此基因才患 色盲，而两个X是否有色盲基因是独立的。 若色盲基因出现概率为0.08。又设男女婴出生比为110:100。问一新生儿有色盲的概率是多少？ 我们来分析这个问题。 设：\"新生儿有色盲\"为事件A，","tags":"数学","title":"全概率公式"},{"url":"sndnyang.github.io/conditional-probability.html","text":"问题引入 讲概念、 讲定义都是太抽象的， 还是从问题开始， 先有个直观的印象。 例一 抽奖 有M个人要抽N张入场券，若某人第k个抽，但在此之前已知前k-1个均未抽到入场券，问此时他抽到的概率是多少， 与不知道前k-1人的状态时的概率相比， 是否有变化？ 设 A：\"第k个人抽到入场券\" B：\"前k-1个人均未抽到入场券\" 已知在不考虑B的情况下， P(A) = N/M 直观分析 原题\"B已经发生的情况下， A的概率\"里包含了几个新的事件， 需要计算概率， 分别是 AB A|B B|A B A or B submit 计算概率 因为本人水平有限， 暂未实现多个填空的问题 所以请自行在草稿纸上计算出 P(B) 和 P(AB) 再进行下一步——如果直接点下一步， 也行 相关 根据 P(AB) 和 P(B), 可知 P(AB)/P(B) = N / (M-k+1) = P(A*) 这样， 我们就发现 P(A*) = P(AB)/P(B) 这是巧合吗？ 例二 人口调查 暂略 例三 肿瘤 暂略 too 总结 根据前面的例子， 可知此时A发生的概率已经有了新的意义。 我们想想， 叫什么？ 在已知B发生的条件下， A发生的概率 有了新定义， 就要引入一个新的记法， 记做 P(A|B) |后面的B 是已知条件 条件概率定义 设A，B为事件，P(B)>0，定义 P(A|B) = P(AB)/P(B) 称为是B发生条件下A发生的概率（conditional probability of the event A given the event B has occurred） 验证条件概率性质 略 乘法公式 虽然最好的方法是从问题来引出 我们需要乘法公式， 但我找不出来例子就算了， 乘法公式太简单了 由条件概率公式变形， 得到乘法公式： P(AB) = P(A|B)P(B) 意义： 计算积事件的概率， 通常可避免计算组合数 独立性即条件概率成立的条件 问题引出 设一个家庭生男孩、女孩是等可能的。 考察任一两个孩子家庭，分别求\"老二是女孩\"的概率和在\"老大是男孩\"的条件下\"老二是女孩\"的概率 一道常识题， 都是50% 设A为\"老二是女孩\",B为\"老大是男孩\" 则 S = {(bb),(bg),(gb),(gg)} A = {(bg),(gg)} B = {(bb),(bg)} AB = {(bg)} 条件概率 P(A|B) = 1/2 结论 上例中条件概率与无条件概率是一样的，说明\"老大是男孩\"这一事件对\"老二是女孩\"这一事件的概率没有影响，或者说这两个事件是独立的。 独立性定义 一般地，若P(A)=P(A|B)，或等价地若P(AB)=P(A)P(B)，称事件A，B独立(independent). 独立性判断 呃， 经验~~~ 多事件独立 事件 \\(A_1,...,A_n $相互独立，指下列 $2&#94;n-n-1\\) 个等式均成立 公式略——任意2到n个事件的组合 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"数学","title":"条件概率"},{"url":"sndnyang.github.io/prob-measure.html","text":"定义 学派 频率派 贝叶斯派 公理化整合 计算概率 频率说： 在系列重复随机试验中， 考察随机事件发生的频率（稳定值） 样本信息 主观说（贝叶斯派）：根据以往的资料或经验， 形成的关于随机事件可能性的印象 先验信息 等可能说（贝叶斯派）：基本事件的发生没有偏向性，都是等可能的 无信息 公理化定义 概率：定义在S（样本空间）的事件族上的实值函数 P， 满足： 非负， $ P(A) \\geq 0 , \\forall A \\in S $ 规范， 必然事件概率为1 P(S) = 1 可列可加， 互斥事件之和的概率 = 各自概率之和 性质 不可能事件概率为零 $ P(\\varnothing) = 0 $ 有限可加性 单调性 事件概率小于等于 1 对立事件 加法公式 推广","tags":"数学","title":"概率-度量可能性"},{"url":"sndnyang.github.io/prob-stat-intro.html","text":"概率直观定义 概率就是一个事情发生的可能性。 但这个感性的认识并不严格， 不能准确地描述 概率定义严格化 研究对象 什么问题（现象、 事件）有可能性？ 这类问题才是概率要研究的内容 很明显， 简单来分， 自然现象可分为两类 确定性现象， 没概率的事 不确定现象(可能) 无规律现象 随机现象：大量重复实验存在统计规律性的现象，概率研究对象 数理统计 研究对象 研究对象： 数据 收集 整理 分析 推断或预测 概率与统计 数理统计为概率论面向实际问题提供联系桥梁。 概率论 为 数理统计方法 的合理性提供理论证明。","tags":"数学","title":"概统介绍"},{"url":"sndnyang.github.io/quick-sort.html","text":"欢迎在zhimind上学习 本教程将尽我所能，指导您理解、练习并掌握快速排序算法。虽然目前仅限于使用javascript, 但算法对其他语言是通用的， 具体的语言不会影响您的理解。 左侧是javascript输入控制台，现在先告诉我们您的名字, 请输入 setName('您的昵称') 另外，有一些有用的命令: 输入 help() 来查看帮助吧！ 排序问题 现实中非常常见的一个问题就是， 给定一堆乱序的数字或名称， 给它们排好序。 之前可能已经学过以下几种排序算法: 冒泡排序 选择排序 插入排序 归并排序 堆排序 我们现在又要用新的方法实现了, 它就是 快速排序 。 在开始正题之前， 先来查看待排序数组 v[] 的数据 ， 请输入 print_list() 分治思想 不同于选择或冒泡排序逐个处理的暴力搜索思想， 我 们现在来考虑分治的思想 划分的方式 从中间位置划分，分后治之的是归并排序。 如果不指定位置划分， 有其他方法划分否？ 另外能否边分边治？ 还有哪些可能的划分方式? 随机 值大小 位置 不知道 submit 怎么选值呢? 不按位置，那我们只能按实际值的大小来划分。 那怎么选划分值呢？ 随机一个 第一个 最后一个 中间那一个 平均值 中位数 不知道 submit 准备划分 既然已经知道了划分的k值， 那么现在就来划分数组了。 目标就是让小于k的数放到左边， 大于等于k的数在右边，k在中间 想法是简单，可这不是废话吗？排好序的就有这性质啊。 那乱序的数组不排序怎么做呢？ 分析初始和目标状态 关于初始状态，只知道 k在数组第一个位置 k左边没有数，为空 右集合是一堆乱序数。 反过来看目标状态，是不是也是三个集合： k自己是一个集合 比k小的数组成一个集合 不比k小的数组成一个集合（除k） 正好对应上 既然如此， 就定义两个空集合（k本身是一个集合）， 分别叫做 left, right. 请写代码 left=[],right=[] 遍历划分 很简单， 我们只要遍历一遍数组v[]，将里面的元素按比k值的大小结果，相应地添加到left和right 请实现， 得到left, right结果 请从第二位开始从左往右遍历， 否则顺序不匹配， 也过不了 递归解决子问题 目前求得三个集合， k, 比k小， 不比k小。 然后要递归处理子问题， 首先， 当问题规模 <= 1时， 不需要再划分， 直接返回该数组-- 作为递归出口 其次， 子问题处理完毕后， 三块集合要连接， 才能向更上层返回。 请基于前面几步， 编写一个递归函数quicksort， 并调用它来处理数组v[] 快速排序优化， 请待后续分解 以上部分是最容易实现的快速排序方法， 但有浪费一些空间， 教科书上最常见的不需要这部分空间, 会有一些小陷阱， 我暂时写不下去了--打算先写点别的 如何求解 所以现在问题就是 如何求 i(index), 就是k的目标位置 从初始状态开始， k 在第一个位置，而js数组下标从0开始， 所以 i = 0 目标位置可以由什么直接决定? 不比k小的个数 比k大的个数 比k小的个数 和k相等的个数 submit 那请找出比 k 小的值的个数 so easy! 请在得到该值后（直接数个数也行），建议用循环比较（文本框问题全部写成一行)，并保存到变量里， 输入 变量或值 哪里不对？ 看起来位置是知道了， 但感觉哪里不对？ 哪里都不对 知道k位置，还不知道左右集合大小 只知道k位置，其他值没说 有哪里不对 submit 能否在计算 k 位置的同时， 把集合划分好？ 之前你是怎么统计 <k 的值的个数的？ 还记得吧？ 从左往右扫描时（或从右往左），假设不扫描k所在的第一位 是不是 看到一个小的数，就加1呢？ 如果求的是 >= k 的个数， 也是类似的， 不是吗？ 做成动画的话， 是不是 k 的位置往右移动了一格呢？ 那有什么问题吗？ 原位置留的坑怎么办？ 不知道看到哪里了？ 新位置的值怎么办？ 这些都不是问题 submit 向右移动到新位置 新位置上的值怎么办？ 只用下标记位置 用临时变量保存起来 submit 原位置怎么办？ 留空 k 我也不知道 随便找个小于k的数填上 正看到的那个小于k的数来填上 submit 顺利？ 上一步有什么问题？ 想想上上一步 新位置上的值是怎么处理的？ 有问题？我不知道 位置只是下标,原位置的实际值会被覆盖 k的位置可能会乱掉 submit 如何避免覆盖？ 当然是 两个位置的值进行交换 用临时变量保存 submit 回顾一下？ 那我们脑海里的动画似乎可以顺利进行了 选择好 k 的值——先假设是数组的第一个数， 当前位置是下标0 数组从左往右扫描时（或从右往左）， 遍历时怎么处理？ 看到一个小于k的数，k的位置向右走一格， 原位置和扫描到的位置进行交换(即小于k的值被移到了k的左边，而在原位置上的数是之前扫描过的不小于k的数，交换后仍然保持在k的右边)。 否则继续遍历， 直到遍历完整个数组。 好， 那我们开始走一遍 先选一个 k 请用代码选出当前数组的第一个值,及下标 i=0;k = ??? ，请不要直接填写具体值 循环遍历 假设从左往右扫描， 都说了边分边治，为什么不呢？难不成还等回来再处理？ 那现在的问题就是， 在我们遍历时， 能不能顺便把小的扔在一起，不小于k的扔在一起？ 假设现在左右两边集合都是空的，遍历时小的放到数组左端， 不小 的加到数组右端， 省略若干字和一步 但想想，这两个集合是互斥的，不重叠的，我把左边的搞好了，k就知道了， 右边自然就剩下并满足了，为什么要小也判断一下，大也判断一下 所以只需要在遍历时， 发现小的就放到数组左端， 像是去排队一样 , 一开始队伍长度为0， 所以我们定义一个变量 var set_length=0 , 也可以用队首队尾概念定为-1，问题都不大 现在请用代码实现 集合长度 变化过程 遍历；逐个处理；（这个暂时没想好 怎么算通过测试， 请随意输入） . 是不是只要知道k 在目标状态时的位置， 并保证左边的都小于k, 右边的都大于等 于k， 就知道左右集合大小了呢， 至于它们内部需要有序吗？我们不管。 分后才治之？ 正确实现 所以整个过程就是， 当遍历到某个值v[i]时， if (v[i]小于k) {v[set_length] = v[i]; set_length++;} 是不是有什么问题呢——对吧， v[set_length] 被覆盖了， 原来的 值就这么随意的get out了吗？所以， 我们不能简单地覆盖， 而是应该交换两个位置的值 下面就请正确实现 整个划分过程吧， 一定要正确地划分！不然不让 过哦， 用很多算法书上的 while 循环或一些算法书上的for循环遍历都 可以，只要满足k 左边的值都小于k,右边的值都不小于k, 请使用已定义 变量 l 或 k 或 global_l, global_k， 代码写成一行 请将 k 目标状态所在位置的值保存在 变量 global_l 中。 参考答案: l = 1; for(var j = 1; j &lt v.length; j++){ // 这个for 循环要写成 一行 if (v[j] &lt k){ swap(v, j, l); l++; } } swap(v, l-1, 0) global_l = l-1; 可以像归并排序那样分完再治吗？ 如果没学过归并排序， 以下几节不用细看 正如之前提到的， 在学习分治算法时， 老师通常会讲 归并排序和快速排序。 如果有学过 归并排序 , 应该有印象， 最常规的归并排序是先不断地递归划分成子问题，直到不可再划分， 等到返回时， 再将子问题进行合并。 所以是先分后治， 分完再治。 那快速排序可以这样吗？我们每层都可以求出划分的位置，是否可以 先递归求子问题， 再返回求解主问题？ 可以 不可以 submit 撒花庆祝！ Congratulations, {{ firstName }}, 你完成了快速排序的学习（中间 少了很多步还没写呢）。 如果觉得有意义, 但没完全掌握或希望复习的话， 用 reset() 重新学习吧！","tags":"算法","title":"快速排序"},{"url":"sndnyang.github.io/random-event.html","text":"随机试验 对随机现象的观测 样本和样本空间 试验的每一种结果就是一个样本s 所有可能的结果 就是样本空间S 随机事件 样本空间的子集 事件运算 类集合运算 省略","tags":"数学","title":"随机事件"},{"url":"sndnyang.github.io/tu-jie-shu-xue-xue-xi-zhi-ju-zhen.html","text":"matrix 矩阵的英文叫 Matrix， 原意是\"母体， 基质\"， 作者认为西方原意是指为了形成一个整体而填充进去的填充物。 所以 $$ \\begin{pmatrix} 1&2 \\\\ 3&4 \\end{pmatrix} $$ 在西方人的眼中很可能是数字填充在了括号的空间里。 用黑客帝国来理解呢？ 其实它的英文名是 matrix, 直译应该是母体的意思， 矩阵是个母体， 里面的数字就是啥？ 其实矩阵的译名应该不错， 矩形不一定对， 但目前只见过矩形的。 阵也是个整体， 个体站在需要的位置上。 原文这段主要在吐槽 日文里的行列译法， 而且应该是跟 他们的队列、 排队 相重了。 还有当年日本文字是竖写的， 行、列的意思与现在相反。 矩阵的出现 矩阵公认是根据方程组发明的。 比如一个方程组 $$ \\begin{equation} \\left\\{ \\begin{aligned} x+5y+2z=9 \\\\ 4x+6y+z=12 \\\\ 9x+3y+3z = 6 \\end{aligned} \\right. \\end{equation} $$ 如果方程式再增多， 写起来就非常烦琐了。 于是数学家经过抽象（也就是偷懒）， 发明了 Matrix 概念。 怎么抽象？ 提取系数 提取未知变量 submit 抽象 没错， 系数和变量分开装， 先是变成了这样(latex公式不太会写)： $$ \\begin{equation} \\begin{aligned} (1 \\ 5 \\ 2) \\\\ (4 \\ 6 \\ 1) \\\\ (9 \\ 3 \\ 3) \\end{aligned} \\times (x \\ y \\ z) = ? \\end{equation} $$ 再把所有数字放进一个括号里， 就成一个整体 A 了， $$ A=\\begin{pmatrix} 1&5&2 \\\\ 4&6&1 \\\\ 9&3&3 \\end{pmatrix} $$ 问题就成了求方程: $$ A*(x \\ y \\ z) = ? $$ 你可能会想:\"A的这些数字之间没联系， 怎么看成整体？\" 所以这就是抽象的威力了， 数学家不只是偷懒， 他们还给矩阵定义了很多严密的规则（运算规则）， 使得大家都认可了这些规则。 所以， 学数学的过程 其实也包括锻炼抽象思维能力， 甚至于具体知识用不上，就只剩下抽象、 逻辑等思维能力了， 不然可以说高等数学真的完全没用。 矩阵的现实意义 之前提到matrix 的原意， 但数学上matrix 矩阵 到底算个什么东西呢？ 教科书上喜欢的定义是： $$ 由 m \\times n 个数组成的 m 行 n列的数表 ， 称为一个 m行n列的矩阵，或 m \\times n 矩阵 $$ 只抽取了数字， 对数字背后潜藏的意义无动于衷。 最关键的是定义加减乘除（貌似很少说除）规则后， 还让你手算~~~ 这样的计算， 只知方法， 不知意义， 就很可能使学生越来越讨厌数学。 原文从销售例子介绍了一堆， 但我觉得 他说的\"看到矩阵， 在脑中就应该浮现出原来的数据表\" 不太现实。 矩阵和数据表 中间还有个方程组这一步， 甚至高观点里矩阵相乘是什么线性变换， 跟现实的市场数据就套不上了。 所以决定直接跳到乘法运算分析这部分(最后面加减也无视了)。 乘法运算为什么是行乘列？ 我们已经得到了一个这样的式子 $$ \\begin{equation} \\begin{pmatrix} 1&5&2 \\\\ 4&6&1 \\\\ 9&3&3 \\end{pmatrix} \\times \\begin{pmatrix} x & y & z \\end{pmatrix} = ? \\end{equation} $$ 不对， 课本上是这样的啊 $$ \\begin{equation} \\begin{pmatrix} 1&5&2 \\\\ 4&6&1 \\\\ 9&3&3 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} \\end{equation} $$ 为什么要竖着排？ 就是这样定义的 节约空间 好玩 不走异常路 不知道 submit 解释 现在解释这个 可能没什么意义， 纯粹科普。 但不好意思的是， 原文里 这段的例子不好打~~~放弃了。 大概意思就是， 如果矩阵乘法使用行乘行的话（不考虑列乘行这种更违背习惯的）， 假设左矩阵（被乘数矩阵？）固定了 那右矩阵再扩展的话， 得纵向延伸也就是继续加新的行， 但计算的结果（矩阵）却是横向延伸，加新的列。 延伸方向不一样。 乘数矩阵添加了第i行， 计算结果矩阵却添加了第i列。 所以改成行乘列的话， 乘数和计算结果矩阵延伸方向就一致， 第j列对应第j列。 符合从左向右看算式的习惯。 不好意思， 内容就这么多~~~ 作者其实在讨论最基本的东西， 可以说 -- 这本书的内容不看也没问题 他重点不是把各种高深的理论解释一遍， 让你全部弄懂。 作者希望的是\"把日常生活和抽象世界（数学）紧紧联系起来， 就能理解数学\"。所以应该是通过他写的这几个例子， 有这方面的意识， 懂得怎么去联系。 说起来， 这话也没错， 但对于有些知识数学知识来说， 很难跟日常生活联系起来。 比如抽象代数群环域， 据说 刚提出时， 连大数学家欧拉都无法理解， 欧拉公式都有点跟现实世界联系不起来了， 何况欧拉看不懂的。 联系的应该是他另外地方说的模板， 也就是包括日常生活经验以及以往的数学知识。 没有模板， 全新的内容学起来就会很痛苦。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"线性代数","title":"图解数学学习之矩阵"},{"url":"sndnyang.github.io/alphago-papers.html","text":"参考文献 原文:Mastering the Game of Go with Deep Neural Networks and Tree Search alphago-原理 郑宇,张钧波 alphago-分析 田渊栋 开源代码 alphago-code 战绩 对欧洲冠军 Fan Hui formal games were 1 hour main time plus 3 periods of 30 seconds byoyomi informal games were 3 periods of 30 seconds byoyomi 对李世石 2016.3.9 alpha胜 2016.3.10 alpha胜 2016.3.12 alpha胜 2016.3.13 李世石胜 2016.3.15 alpha胜 期待与柯洁的对战 李世石重下战书 基本定义 棋盘状态 动作 action a : action 动作 暴搜不可行！！！ 组合爆炸！！！ 围棋的可能状态数大约在 250&#94;150 国际象棋 35&#94;80 策略 减少搜索树的深度， 即先行评估位置， 避免深度递归 减少搜索树的广度， 即减少可能动作分支 方法 步骤 用棋谱数据 训练 监督学习策略(走棋)网络, 同时训练快速走子策略 对策略网络进行强化学习， 程序自我对弈 训练一个价值网络， 预测胜率 用MCTS 结合策略网络和价值网络 组成 链接：http://zhuanlan.zhihu.com/yuandong/20607684 来源：知乎 走棋网络（Policy Network），给定当前局面，预测/采样下一步的走棋。 快速走子（Fast rollout），目标和1一样，但在适当牺牲走棋质量的条件下，速度要比1快1000倍。 估值网络（Value Network），给定当前局面，估计是白胜还是黑胜。 蒙特卡罗树搜索（Monte Carlo Tree Search，MCTS)，把以上这三个部分连起来，形成一个完整的系统。 一. 策略网络学习 监督学习 训练集数据： KGS 专业棋手(5-9段)的棋谱， 大概16万局棋， 3千万种棋盘状态 学习到一个预测模型 g 状态S 预测模型 g:S->p(a|S) 概率 p(a|S) 概率最大的动作 a 模型学习算法 深度学习： Convolutional Neural Network (CNN)， 卷积神经网络 围棋对局势的评估很难建模， 抽象 CNN正好擅长抽象 另用线性模型训练快速策略 随机梯度下降 预测 输入： 棋盘状态S 输出： 所有合法动作a 的概率分布 二. 策略网络强化 对弈激励 当前版本的策略网络 与 随机的一个版本 胜 z_t = +1, 负= -1, 未结束=0 瓶颈 强化学习 存在理论瓶颈， 而且应该是被证明了， 没记。 三. 价值网络强化 步骤 输入状态S, 经过 普通策略网络 生成前 U-1步 随机采样 决定 第U步 增强策略网络 完成剩下博弈 胜负作为输出 得到价值网络， 判断该盘面的输赢概率 reduce 搜索空间的方案 减少搜索树的深度， 价值网络 value network 减少搜索树的广度， 策略网络 policy network 四. monte-carlo 树搜索 步骤 选择， 用策略网络剪枝 扩展 评估， 使用价值网络 回溯 树的组成 对 每条边(状态s, 动作a) 动作值 action value Q(s, a) 访问次数 visit count N(s, a) 先验概率 prior probability P(s, a), 初始化为 策略网络值 p(a|s) 图示： 描述 根据 ， 找到叶子结点 用策略网络计算所有可能下一步的概率， 逐个进行3 用价值网络和快速走子策略评估","tags":"研究","title":"alphago-总结"},{"url":"sndnyang.github.io/classical-music-week1.html","text":"4. 音乐传播过程-声波和耳朵 长波低音高， 短波高音高 空气（外耳） - 内耳 - 电化学信号 - basilar membrane（耳蜗基底膜） - 纤毛感应特定声波 - 大脑 - primary auditory nerve - auditory cortex(大脑皮层) in temporal lobe 其他相关： 1. prefrontal cortex(lobe) -- where am i in this piece 2. motor cortex parietal lobe -- movement 3. hippocampus - memory 4. limbic system, amygdala -- emotion 5. ... 6. why we like what we like. 对音乐模板、模式(template)的预测方式 nurture -- 文化培养 nature 7. 西方音乐的语法syntax leading tone -- pull toward the home pitch or tonic large leap -- reversed by following pitch harmony -- must fit with the melody chord progression -- harmonies usually return home to tonic 8. 音乐的本质 nature overtone series 乐器震动出声时， 其实不只一个音， 只是听觉系统让我们只听到最低音， 因为它声音最大 这个最低音振幅最大， 定为 fundamental tone , 其他音 overtones 后面几个音和前面做和音","tags":"音乐","title":"古典音乐导论-第一周"},{"url":"sndnyang.github.io/multi_layer_cd_suver.html","text":"摘要 Community Detection in Multi-Layer Graphs: A Survey 本文介绍多层网络下聚落检测问题， 并对相应算法做综述 导论 - 过 背景知识 群落/社区 community densely-connected components/subgraph relative/similar 比如： 同校、 同系、 同班是一个 community 同一个社团、 公司 同一领域的研究 多层网络模型 关系的不同方面就可以表达成多个独立图组成的多层图， 里面的每个、每层图就代表了一个方面 比如： 同学关系 微信好友 微博好友 单层图定义 a weighted graph (V,w) V is a set of vertices w is a set of edge weights: (V × V ) → [0,1]. 点映射(图层之间) node mapping is a function from a graph layer L1 = (V1 ,w1 ) to another graph layer L2 = (V2 ,w2 ) V1 × V2 → [0,1]. For each u ∈ V 1 , the set C(u) = {v ∈ V2 |f(u,v) > 0} is the set of V2 vertices corresponding to u. 对于一个facebook上的账号（个人）： twitter 上没有账号 twitter 上只有一个号--pillar(柱型) multi-layer graph twitter 上多个号 多层图定义 a tuple MLN = (L1 ,...,Ll ,IM) where Li = (Vi ,wi ),i ∈ 1,...,l are graph layers IM (Identity Mapping) is an l ×l matrix of node mappings, with $ IM_{i,j} : V_i ×V_j → [0,1] $ 例： 症状 疾病名 细菌、病毒或基因 信息网络定义： 是个有向图， 存在\"点\"到\"点类别\" 的函数映射 及 \"边\"到\"关系(边)类别\"的函数映射 异构信息网络 Heterogeneous Information Networks 点的类别 或 关系的类别个数大于1的信息网络。 异构信息网络与多层网络模型 等价 但强调不太相同 heterogeneous information networks emphasize heterogeneous types of entities connected by different relationships 主要方法 分类 聚类扩展 cluster expansion 矩阵分解 matrix factorization 统一距离？ unified distance 基于概率模型 model based 模式挖掘 pattern mining 图合并 graph merging 特点 多数只支持两层图 一层是图的原始拓扑结构信息 其他层一般是利用点的属性信息来计算相似度 聚类扩展 Cluster Expansion 论文： Scalable community discovery on textual data with relations 基于关系（文章引用）与文本属性 针对的问题 大型文档语料 -- large cocument corpus 没有同时考虑 textual attribute 和 relations(文献里的引用？) 大数据集的可扩展性scalability 多数算法基于一堆要（人工）设定的参数 思路 非监督方法 快速地找到初始的核， 作为群落的种子 核进行扩展（或合并merge)， 扩展成群落，（提高scalability) cores dictate the formation and topics of communities 核 用来表示 社区的构造和主题 步骤 4 steps: core probing core merging, 根据主题相似度进行合并 affiliation, 利用关系信息，将core扩展成初始社区 classification， 主题不相关的成员从社区中移除 第一步 Core Probing 基本思想 co-occurrence analysis: multiple objects are linked simultaneously by others, they are more likely to be able to define a coherent topic scope prob 步骤 生成每个点的outgoing relations 用关联规则来计算频繁项集(Apriori) 与 Apriori 的不同点 不使用固定的过滤阈值， 根据项集的长度决定阈值 项集存在包含关系，如果项集 S1 和 S2存在 $ S1 \\in S2 $, 不保留S1 core merging 保证了合并后核的高度一致性， 不受过滤阈值的影响 证明过程略 步骤 输入参数: core probing 返回的核 迭代： 对S中任意一对核Ki, Kj， 如果重叠， 转2 计算p-min, p-max, p- 如果 Ki, Kj的交集不为空，且 pi- 或 pj- 属于 该交集， 转4 从S 中移除Ki, 和 Kj, 加入Ki,Kj的并集。 如果遍历完， S 没有变化， 则退出 计算 p-min, p-max, p- p-min, pmax: 在特征空间内， 为 core生成了边界框 p- : 中心 图示： Affiliation Propagation 完成cores probe后，剩余的点作为 affiliated members 初始化社区C = 找到的核K ， 迭代处理： 对K中的每个点d，把所有的、其他的、能连到d的点u 加到C中 设定迭代次数， 避免关系环 或迭代中 没有新的点加入 相关概念 好像没什么用 两个社区的公共成员则为 interdisciplinary member 点和社区间的相近度(closeness)用迭代时的次数代表 Intra-Community Classification 只根据relation找到的社区 很可能误判(false hits) 要根据属性分析， 将当前的C 划分成两个集合， C' 和 C- 步骤 核K 视作是 positive example正例， 即肯定属于这个社区 选择社区C的核K（正例） 和 其他社区的核（negative example) 将所有点转换成 特征向量（feature vector）来代表它们的topical position 使用 LDA（Latent Dirichlet Allocation）来降维 使用某种分类器（SVM），将负标签的点都移除 图示 主要贡献 用关联规则、频繁项集来初始化 统一距离 Unified Distance structural and attribute similarities using a unified distance measure SA-Cluster 步骤 建立统一距离度量， 新的图 用新的图 进行聚类， 类k-means unified distance measure 基于属性增广图(attribute-argmented graph), 使用Random Walk with Restart (RWR) 邻点随机游走距离 Neighborhood Random Walk Distance l as the length that a random walk can go c ∈ (0, 1) as the restart probability attribute-argmented graph 添加属性点（attribute vertices），代表属性的值。 原始的点连接到对应的属性点上 两点上共同的属性点越多， 两点相似度直觉上就越高。 聚类算法 利用unified distance measure， 进行 k-medoids clustering（类似 k-means） 选择每个聚簇(cluster)最中心的点 其余点分配给最近的中心点。 迭代， 调整边的权重 聚类中心初始化 思想： 从vi走 l 步能到的点越多， vi越可能是中心 计算点的密度函数： 降序排列， 选择前k点作为聚类中心 聚类过程 分配点到最近的中心，即有最大random walk distance的中心点 对每个cluster ,用随机游走距离 计算\"平均点\" 寻找新的中心点，距\"平均点\"最近 不停迭代， 直到 聚类目标函数 收敛 聚类目标函数 目标是最大化 问题转化 有以上的目标函数后， 可转化成三个子问题 聚类分配 中心更新 权重调整 权重自我调整 在每次迭代时， 进行权重调整 属性 ai 权重在第t+1次迭代的计算公式为： 投票机制 majority voting mechanism counts the number of vertices within clusters that share the same attribute values with the centroids on ai 主要贡献 一个统一的距离评估方式， 将结构和属性相似度结合 带权重的自调整方法， 调节结构属性相似度的重要度 基于模型方法 Model-Based Method model-based community detection approach based on both structural and attribute aspects of a graph 步骤关键点 概率模型的构建， 结合结构和属性信息， 不使用人工定义的距离 变分法(variational approach)解决模型 构建概率模型 聚类属性图定义： X: n x n 的邻接矩阵 Y: n x t 的属性矩阵 Z: n x 1 的聚类向量， 即每个点所属的聚类 目标： 求最优化： 其中 联合概率分布 alpha - 每个聚类的点分布（vertex distribution) theta - 属性分布(attribute distribution) phi - 类间 边出现概率(edge occurrence prob) 两大问题 Z 的N个变量最大化 计算量过大， 全局最优基本不可能 计算Z的后验概率分布时， 不存在 p(Z|X,Y)的closed-form expression 变分法 variational algorithm 使用variational distribution q(α, θ, φ, Z) 来逼近原分布 并且对 variational distribution 作限制 全局最优就转成求局部最优 两个新问题 如何定义the family of variational distributions 如何从中找出最优分布， 最接近p(α, θ, φ, Z|X, Y) Parametric Family Optimizing Variational Parameters measure the distance between a variational distribution q(α, θ, φ, Z) and the true posterior p(α, θ, φ, Z|X, Y) 等价于 最大化 关系式： 图合并 Graph Merging combine structural and attribute information using the graph merging process CODICIL 步骤 创建内容边 create content edges 边组合 combining edges 边采样 sampling edges with bias 聚类 clustering creating content edges 对每个点vi, 用cosine相似度， 计算k 内容最近邻 在vi 和 k近邻间 建立content edges combining edges 将新创建的content edges 和 初始的拓扑边集进行简单的联合(unified) sampling edges with bias 对每个点 vi， 从邻点选择要保留的边， 通过 cosine 相似度或Jaccard 相似度 clustering 因为图合并部分独立于community detection， 所以任意 community detection 都可以， 这块不是本文的重点 主要贡献 通过 用内容信息消除连接结构里的噪音， 来强化社区信号 矩阵分解 Matrix Factorization 论文： Community Detection with Edge Content in Social Media Networks Edge-Induced Matrix Factorization 主要idea 通过从多层图中抽取相同因子(common factors) 把不同信息进行结合 使用通用的聚类方法处理 方法 使用 低秩矩阵因子分解(low-rank matrix factorization) 来逼近目标矩阵O， P: n x n 的特征矩阵 lambda(大写的？): n x n 特征值矩阵 目标 对于多个目标矩阵O&#94;i, i = 1,-,l 要算出一个common factor matrix 求最小化： P: n x n的所有层 公因子矩阵 Λ&#94;i: n x n 矩阵， 第i层的特征 || ·|| is the Frobenius norm α: regularization 参数 全局转局部最优 迭代处理： 固定P , 优化 Λ&#94;i 固定Λ&#94;i , 优化 P 直到 收敛 模式挖掘 Pattern Mining Coherent Closed Quasi-Clique Discovery from Large Dense Graph Databases Cocain 方法 子图挖掘算法， 搜索多层图中频率高于某给定阈值的 quasi-cliques 基础定义 gamma(γ)-Quasi-clique cross-graph quasi-clique: a set of vertices belonging to a quasi-clique appears on all layers must be the maximal set Edge Cut, Edge Connectivity edge cut is a set of edges Ec such that G'=(V ,E-Ec) is disconnected A minimum cut is the smallest set among all edge cuts. The edge connectivity of G, denoted by κ(G), is the size of the minimum cut coherent subgraph: a subgraph that satisfies a minimum cut bound gamma(γ)-Isomorphism 同构 若两个图G1, G2是 gamma同构， 当且仅当： 都是 γgamma-quasi-cliques 点个数相同 存在 biject f:V1->V2, 对V1中的每个点v, 满足F1(v) = F2(f(v)) multiset 点的标签的集合(a bag of vertex labels) 忽略顺序 突出多样性 定义为 M(G)， G的multiset string of a graph Given a k-graph g, any sequence of all elements in M(g) 给定 k-graph g, M(g)的任意一种序列 canonical form of a graph the minimum string among all its strings and denoted by CF(G) 图的最小 string, 记作 CF(G) 有引理： 两个γ-quasi-cliques Q1 Q2 是γ同构， 当且仅当 CF(Q1) = CF(Q2) 步骤 将子图转成 canonical forms 枚举γ-quasi-cliques可行解(feasible candidate for γ-quasi-cliques), 用DFS策略进行剪枝 基于 闭包检查规划(closure-checking scheme)， 选择出闭包的 γ-quasi-cliques 枚举策略 枚举树 满足： 子代必须能归入祖先 关键： 对每个 quasi-clique Q, 处理完它的子代后， 进行闭包检查 主要贡献 find cross-graph quasi-cliques in a multi-layer graph that are frequent, coherent, and closed 另一篇模式挖掘 论文 论文： Mining Coherent Subgraphs in Multi-Layer Graphs with Edge Labels 本文贡献 提出了带边标签的多层图聚类的新范式 提出了MLCS, 避免了结果集的冗余 提出了最好优先搜索算法MiMAG 来求MLCS聚类的近似解 multi-layer coherent subgraph (MLCS) model clusters of vertices that are densely connected by edges with similar labels in a subset of the graph layers 找聚类， 满足条件：在某层的图中，不仅边的密度高，且具有相似的标签。 the edge labels represent characteristics of the relations quasi-clique One-dimensional MLCS cluster One-dimensional MLCS cluster 某一图（层）的点集满足以下条件： 形成一个 0.5-quasi-clique 点集的每条边的两个顶点： dist(l_i(x), l_i(y)) <= w, edge label 为连续值时需要w, 不然置为0. 多层 MLCS cluster 冗余关系 redundancey relation MiMAG 算法 Mining Multi-layered, Attributed Graphs 计算出最大化、 无冗余、 高质量（不是最优质量）的聚类 基于寻找quasi-cliques的快速算法。 总结 Apriori 频繁项集的， 特例或通用 随机游走 概率模型 矩阵分解 clique community 没有严格定义 未来研究方向 通用多层图的适应性 General multi-layer graph applicability 当前算法一般仅研究了 pillar(柱形)多层图 现实世界不保证不同层之间正好一一对应 所以现有算法的泛化， 对通用多层图的适应性非常有意义 多层图的不确定性 Uncertainty in multi-layer graphs 现有的研究都假定 图数据已经清理完毕， 缺少噪音、歧义的研究 constructing multi-layer graphs with entity resolution and/or trustworthy analysis certainly enhances the quality of the community detection process 可扩展性问题 所以可能要考虑并行及分布式之类的方法 或是对多层图的特征向量矩阵（feature-vector matrices）进行采样 Temporal analysis 图是随时间变化的。 目前存在一些对单层图的时间变化的研究， 但基本不可用于多层图 谢谢！","tags":"研究","title":"多层网络聚落检测综述"},{"url":"sndnyang.github.io/GaoCD.html","text":"导论 算法思路 通过 划分密度(partition density) 这个目标函数的最优化来寻找 连接群落link communities 通过 novel genotype representation method, 将 连接群落映射回 点群落。 群落数自动发现 算法描述 框架 目标函数 partition density D only considers the link density within the community, different from the common community definition that a community should be densely intra-connected and sparsely connected with the rest communities.# 划分密度D $$ D(c) = \\frac{m_c - (n_c - 1)}{\\frac{n_c(n_c-1)}{2} - (n_c-1)} $$ partition density D is the average of Dc over all communities $$ D = \\frac{2}{M}\\sum_c m_c\\frac{m_c - (n_c - 1)}{(n_c-2)(n_c-1)} $$ 3.3 基因表达 编码 基于连接的表示方法， 群体中的个体g 有 m 个基因， 下标i 代表边的序号 m 是边数——吓死人了。 gj 从连接的点中选一个。 当无向图中两边共点时， 两边相连 解码 把基因型转化成 分割（由连接群落组成）， gi 作为基因型， 值 j 可看作是边 i 和 边 j 有一个共同点， 并应该归入同一群落中。 桥接边： 连接两个 聚落的边。 Fine tuning: 调整 单一映射方法得到的点群落 的点附属关系 寻找有多附属关系的点 membership 计算这种点 对各群落是否有贡献——如果加入的话。 贡献计算方法： $$ AD(c) = 2 * \\frac{|E(c)|}/{|c|} $$ 添加点后， EC 上升， 则OK if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"研究","title":"GaoCD-总结"},{"url":"sndnyang.github.io/ema_comminities_dynamic_networks.html","text":"摘要： 目标： 最大化当前数据的聚类准确性 最小化阶段过渡时的聚类漂移 clustering drift 新概念： temporal smoothness 短时平滑性 snapshot quality , temporal quality 快照质量和短时质量 优点： provides a solution representing the best trade-off between the accuracy of the clustering obtained, and the deviation from one time step to the successive. 为聚类的准确性及阶段过渡时的变动提出了一个最优折衷的方案 ** 问题是这几个东西都不是这篇文章提的概念， 只是函数可能有变化 导言 进化聚类方法(evolutionary clustering) 利用 temporal smoothness 框架。 核心假设： abrupt changes of clustering in a short time period are not desirable （译： 短时间内聚类突变是不值得要的？不合适的？） it smooths each community over time 平滑性的实现 折衷： snapshot quality: 在当前阶段所拥有数据下， 聚类要尽可能精确。 temporal cost: 每个聚类在阶段过渡时， 不能发生剧烈变化。 本文方法 名字： DYNMOGA (DYNamic MultiObjective Genetic Algorithms) 目标 最大化 snapshot quality, 表明当前聚类效果（准确性）， 为此调整了 modularity 的概念 最小化 temporal cost， 表明两阶段间聚类差别， 为此去计算 归一化互信息(normalized mutual information) 优势 利用这两个方法的优势 选择性搜索解空间， 不需要提前知道 聚类个数。 本文主要贡献 将动态网络中群落结构的检测问题 建模成 多目标优化问题--以前肯定有人弄过了，也算贡献？ 本方法可以考虑成 通用框架，应用于进化聚类。 仅仅需要修改目标函数，测试不同的质量函数--别人的算法也可以，这篇就是利用别人的框架。 本方法不需要参数， 不需要为快照和短时成本设置权重， 也不用设定聚类个数--不知道他人工作情况。 相关工作 主要工作 Evolutionary Clustering by Chakrabarti et al. in [13] 认为changes of connections in short time periods could be caused by noise. 提出了 temporal smoothness 和 snapshot cost temporal cost 问题是： not allow that the number of communities varies over time FacetNet by Lin et al[5] particle-and-density based clustering method by Kim and Han [3] 这些方法的主要问题 聚类个数 不知道。 相对于要选择 参数 alpha 去应用于 temporal smoothness。 DYNMOGA算法 DYNMOGA has been adapted with a customized population type that suitably represents a partitioning of a network and endowed with two complementary objectives 他们使用了 matlab 实现的 NSGA-II 算法框架, DYNMOGA支持 定制的、可表示网络分割情况的群体类型, 并具有两种互补的目标（然而并没有说是哪两种）。 目标函数 定义 \\($\\) CR&#94;t = { C&#94;t_1, ... C&#94;t_k } 是图在 t 阶段的聚类结果 一个聚类中有 n_S 个结点 m_S 条边。 m_S(u) = {v | v \\in C_t } 是结点u 在聚类C&#94;t 的邻点个数 c_S = { (u, v) | u \\in C&#94;t, v \\notin C&#94;t} 是聚类C&#94;t边界的边数。 l_S 是 只连接 模块 C&#94;t_S 内部结点 的边总数。 d_S 是 C&#94;t_S 中点的度数之和 \\($\\) 多种分值定义 Q: the first term of each summand is the fraction of edges inside a community, while the second one is the expected value of the fraction of edges that would be in the network if edges fall at random without regard to the community structure. Values approaching 1 indicate strong community structure modularity 颗粒度 ： $$ Q = \\sum&#94;k_{s=1}[\\frac{l_s}{m} - (\\frac{d_s}{2m})&#94;2] $$ conductance 导率, the fraction of edges pointing outside the clustering： $$ CO = \\sum&#94;k_{S=1}\\frac{c_S}{2m_S+c_S} $$ Normalized Cut 归一化分割 the fraction of total edge connections to all the nodes in the graph: $$ NC = \\sum&#94;k_{S=1}\\frac{c_S}{2m_S+c_S} + \\frac{c_S}{2(m-m_S)+c_S} $$ Community Score 群落分值, measure the fraction of internal edges of each cluster per nodes： $$ CS = \\sum&#94;k_{s=1}(\\sum_{u \\in C&#94;t}(\\frac{m_S(v)}{n_S})&#94;2) * \\frac{2m_S}{n_S} $$ 基因表达 locus-based adjacency representation [34] 每个个体包含 n 个基因， n 指代 结点的个数 每个基因 取值范围 1-n， 即第i个基因与第j个基因之间有连接，该划分到同一群落 ** 注： 这种表达肯定不能用于 群落重叠问题——然而 现实是， 主流用法 就是这样，大同小异 好处： 由个体组成部分的个数，在解码步骤中自动得到 decoding step 解码 使用并查集 建立并查集 makeset 对每条边去查找, findset 查到后的进行合并 初始化 一个有若干个体的群体， 对每个点i, 在邻接点中随机选择一个作为值， 表示 存在边 (i,j) uniform crossover 均匀交叉 给定两个父辈个体， 创建一个随机二元mask, 进行选择， 当 mask 为0时， 取第一个父辈个体的基因（值）， 为1时， 取第二个父辈个体。 如此组成子代的基因 突变 与初始化类似， 对结点i 随机变更值成其他邻点。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"研究","title":"进化多目标方法在动态网络聚落检测中的应用-总结"},{"url":"sndnyang.github.io/ea_based_communities_survey.html","text":"网络相关背景知识 定义 群落检测没有标准定义， 目前一般视为： 一组顶点，之间可能有着共同的属性或在图中起到相似的作用 分类 common model 共同？普通？模型 directed model 有向图模型 signed model 正负向模型 overlapping model 重叠模型 dynamic model 动态模型 进化算法与多目标优化 进化算法 相同性质： 省 框架： Algorithm 1 General framework of EAs 输入： 参数与问题实例 输出： 最优方案 Begin: population initialisation store optimal solutions for i = 1 to max_iteration do for each individual in the population do generate a new individual through stochastic components evaluate the fitness of the new individual endfor update optimal solutions endfor End 多目标优化 定义： 略 Pareto optimal solution: 待看书， 此处略 适应函数 单目标优化 4.1.1 基于颗粒度的模型 因为目标是多目标优化，先略， 如果有用再回来看 4.1.2 multi-resolution model 多分辨率？模型 同上 4.2 多目标优化 其他model 略 重叠模型 操作子 设计 个体表示 个体重现 个体局部搜索 结论 主要思想： 将群落检测建模成 单目标或多目标优化问题 设计元启发方法来解决 问题一： 根据 no free lunch 理论， 没有通用方法能解决全部类型的网络 不同网络的时-空特性不同 问题二： 由于数据集过大， 基于元启发方法的群落检测是LSGO问题（大规模全局优化）， 包含大量的决策变量，对现存优化技术是个挑战。 如何又快又好就值得思考 网络群落问题将超越纯粹结构分析，变成强调网络智能。","tags":"研究","title":"基于进化算法的群落检测问题综述总结"},{"url":"sndnyang.github.io/overlap_communities_survey.html","text":"算法 1. Clique Percolation 中文名？派系过滤 假设 群落由 完全连通子图的重叠集合组成——a community consists of overlapping sets of fully connected subgraphs 思路 detects communities by searching for adjacent cliques 扩展内容 派系(Cliques)。在一个无向网络图中，\"派系\"指的是至少包含3个点的最大完备子图。这个概念包含3层含义：①一个派系至少包含三个点。②派系是完备的，根据完备图的定义，派系中任何两点之间都存在直接联系。③派系是\"最大\"的，即向这个子图中增加任何一点，将改变其\"完备\"的性质。 n-派系(n-Cliques)。对于一个总图来说，如果其中的一个子图满足如下条件，就称之为n-派系：在该子图中，任何两点之间在总图中的距离(即捷径的长度)最大不超过n。从形式化角度说，令d(i,j)代表两点和n在总图中的距离，那么一个n-派系的形式化定义就是一个满足如下条件的拥有点集的子图，即：d(i,J)\\le n，对于所有的，n_i,n_j\\in N,来说，在总图中不存在与子图中的任何点的距离不超过n的点。 n-宗派(n—Clan)。所谓n-宗派(n—Clan)是指满足以下条件的n-派系，即其中任何两点之间的捷径的距离都不超过n。可见，所有的n-宗派都是n-派系。 k-丛(k-Plex)。一个k-丛就是满足下列条件的一个凝聚子群，即在这样一个子群中，每个点都至少与除了k个点之外的其他点直接相连。也就是说，当这个凝聚子群的规模为n时，其中每个点至少都与该凝聚子群中n-k个点有直接联系，即每个点的度数都至少为n—k。 某个的步骤之一 begins by identifying all cliques of size k in a network, a new graph is constructed such that each vertex represents one of these k-cliques 结论 more like pattern matching rather than finding communities since they aim to find specific, localized structure in a network. 2. Line Graph and Link Partitioning 中文名？连接划分 思路 partitioning links A node in the original graph is called overlapping if links connected to it are put in more than one cluster. 3. Local Expansion and Optimization 中文名？局部增广和优化 思路 based on growing a natural community or a partial community rely on a local benefit function that characterizes the quality of a densely connected group of nodes 4. Fuzzy Detection 中文名？模糊检测 思路 quantify the strength of association between all pairs of nodes and communities 例子 Non-negative Matrix Factorization 5. Agent-Based and Dynamical Algorithms 中文名？基于啥的动态算法 思路 label propagation algorithm by allowing a node to have multiple labels 6. others 中文名——无法分类 :) 评估方法 1. Normalized Mutual Information 中文名？标准互信息 2. Omega Index 结论","tags":"研究","title":"群落覆盖问题总结"},{"url":"sndnyang.github.io/findbugs_summary.html","text":"原文: Finding Bugs is Easy by David Hovemeyer, William Pugh 摘要 旧方法基于 formal methods 和 复杂程序分析， 难用， 无作用 bug patterns - detectors 简单的自动技术在遇到常规错误和难解特性时都有用 导论 conclusion 不存在这种bug, 过于明显，以至于在实际代码中没有找到例子——发现的bug中，有些十分明显， 让我们吃惊， 即使是在生产应用和库里 现代OO语言的高度复杂性， 对语言特性及API的滥用是屡见不鲜的。 自动bug检测可以在 程序正确性 上起到巨大作用","tags":"研究","title":"FindBugs总结"},{"url":"sndnyang.github.io/human_kernel_summary.html","text":"bayesian nonparametric models such as Gaussian processes function extrapolation problems kernel learning framework ** reverse the human-like and inductive biases of human across a set of behavioral experiments to gain psychological insights and to extrapolate in human model ability determined by its support(which solutions are a priori possible ) inductive biases (which solutions are a priori likely) controlled by a covariance kernel","tags":"研究","title":"human kernel 总结"},{"url":"sndnyang.github.io/FOCS_summary.html","text":"基本定义 图： G(V, E) 目标—— 找到一簇子图(全部并正确)， 每个子图都是一个团（community) 即 $ S = {S_i | S_i \\subset V } $ 团（community)： 子图中任意点在该子图中的连通性 高于 非团的子图 定义 包含点 $ v_j $ 的团的集合为： $$ S(v_j) = \\{S_i | v_j \\in S_i \\land S_i \\in S \\} $$ disjoint cluster: $$ |S(v_j)| \\le 1 $$ overlapped cluster: > 1 定义 \\( N(v_j) $ 为 $v_j\\) 的邻接点 定义 \\( N_i(v_j) $ 为 $v_j\\) 在团 \\(S_i\\) 的邻接点， 即 $$ N_i(v_j) =\\{v_k | (v_j, v_k) \\in E \\land v_k \\in S_i \\} $$ 新概念定义 团连通性 community connectedness, 即点 \\(v_j\\) 在团 \\(S_i\\) 邻点超阈值个数 除以 该团点数, 代表 点对应团的归属性。 $$ \\zeta&#94;i_j = \\frac{|N_i(v_j)|-K+1}{|S_i| - K} if |N_i(v_j)| > K, else, 0 $$ 邻接连通性 neighborhood connectedness， 即 点 \\(v_j\\) 在团 \\(S_i\\) 邻点数 除以 \\(v_j\\) 的总邻点数， 代表 点加入新团的可能性 $$ \\xi&#94;i_j = \\frac{|N_i(v_j)|}{|N(v_j)|} $$ 外围结点 peripheral node: \\(v_i\\) 的团邻接点 $$ Added_i = \\{v_k|v_k \\in N(v_i) \\land v_k \\in S_i \\}, \\forall S_i \\in S&#94;l $$ 步骤 初始化 初始化全部有K个以上邻接点的点， 由它及其邻接点组成团 \\(S_i\\) 定义该阶段的外围结点 脱离阶段 对前面所有团里的点 \\( V_j\\) , 计算相应的 团连通性 $ \\zeta&#94;i_j $ 邻接连通性 $ \\xi&#94;i_j $ 将[0, 1] 区间划分为 \\(max(20, N(v_j))\\) 块， 每块初始化为0. 根据团连通性分数， 统计各区间 点的个数。 标记 最右的非0元， 并开始向左遍历， 直到： 遍历完毕 或 遇到某区间，<=标记值(最右非零元)， 且<=左边区间值， 这个值选为 留存阈值 stay cut-of of \\zeta 外围结点 \\(v_k \\in Added_i $ 排除出 $S_i\\) , 当团连通性分数 $ \\zeta&#94;i_k $ 比留存阈值低。 Removal of only peripheral nodes ensures that nodes that form the core of a community are never eliminated 扩充阶段 对上一阶段处理后的团中所有点 \\(v_j\\) ， 当以下条件满足： 1. 该点未入 \\( S_i\\) 团 2. 该点选入 \\(S_i\\) 团的可能性高（即 邻接连通性 \\(\\xi&#94;i_j\\) 高于选中阈值 join cut-off ） join cut-off 选中阈值的计算方式与 stay 相同 去重阶段 代码描述 参考链接 focs-code /*! * * IPython notebook * */.ansibold{font-weight:700}.ansiblack{}.ansired{color:#8b0000}.ansigreen{6400}.ansiyellow{color:#c4a000}.ansiblue{8b}.ansipurple{color:#9400d3}.ansicyan{color:#4682b4}.ansigray{color:gray}.ansibgblack{background-}.ansibgred{background-color:red}.ansibggreen{background-color:green}.ansibgyellow{background-color:#ff0}.ansibgblue{background-f}.ansibgpurple{background-color:#ff00ff}.ansibgcyan{background-ff}.ansibggray{background-color:gray}div.cell{border:1px solid transparent;display:-webkit-box;-webkit-box-orient:vertical;display:-moz-box;-moz-box-orient:vertical;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch;border-radius:2px;box-sizing:border-box;-moz-box-sizing:border-box;border-width:thin;border-style:solid;width:100%;padding:5px;margin:0;outline:0}div.cell.selected{border-color:#ababab}@media print{div.cell.selected{border-color:transparent}}.edit_mode div.cell.selected{border-color:green}.prompt{min-width:14ex;padding:.4em;margin:0;font-family:monospace;text-align:right;line-height:1.21429em}div.inner_cell{display:-webkit-box;-webkit-box-orient:vertical;display:-moz-box;-moz-box-orient:vertical;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch;-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1}@-moz-document url-prefix(){div.inner_cell{overflow-x:hidden}}div.input_area{border:1px solid #cfcfcf;border-radius:2px;background:#f7f7f7;line-height:1.21429em}div.prompt:empty{padding-top:0;padding-bottom:0}div.unrecognized_cell{padding:5px 5px 5px 0;display:-webkit-box;-webkit-box-orient:horizontal;display:-moz-box;-moz-box-orient:horizontal;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}div.unrecognized_cell .inner_cell{border-radius:2px;padding:5px;font-weight:700;color:red;border:1px solid #cfcfcf;background:#eaeaea}div.unrecognized_cell .inner_cell a,div.unrecognized_cell .inner_cell a:hover{color:inherit;text-decoration:none}@media (max-width:540px){.prompt{text-align:left}div.unrecognized_cell>div.prompt{display:none}}div.code_cell{}div.input{page-break-inside:avoid;display:-webkit-box;-webkit-box-orient:horizontal;display:-moz-box;-moz-box-orient:horizontal;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}@media (max-width:540px){div.input{-webkit-box-orient:vertical;-moz-box-orient:vertical;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}}div.input_prompt{color:navy;border-top:1px solid transparent}div.input_area>div.highlight{margin:.4em;border:none;padding:0;background-color:transparent}div.input_area>div.highlight>pre{margin:0;border:none;padding:0;background-color:transparent}.CodeMirror{line-height:1.21429em;font-size:14px;height:auto;background:0 0}.CodeMirror-scroll{overflow-y:hidden;overflow-x:auto}.CodeMirror-lines{padding:.4em}.CodeMirror-linenumber{padding:0 8px 0 4px}.CodeMirror-gutters{border-bottom-left-radius:2px;border-top-left-radius:2px}.CodeMirror pre{padding:0;border:0;border-radius:0}.highlight-base,.highlight-variable{}.highlight-variable-2{color:#1a1a1a}.highlight-variable-3{color:#333}.highlight-string{color:#BA2121}.highlight-comment{color:#408080;font-style:italic}.highlight-number{80}.highlight-atom{color:#88F}.highlight-keyword{color:green;font-weight:700}.highlight-builtin{color:green}.highlight-error{color:red}.highlight-operator{color:#A2F;font-weight:700}.highlight-meta{color:#A2F}.highlight-def{f}.highlight-string-2{color:#f50}.highlight-qualifier{color:#555}.highlight-bracket{color:#997}.highlight-tag{color:#170}.highlight-attribute{c}.highlight-header{f}.highlight-quote{90}.highlight-link{c}.cm-s-ipython span.cm-keyword{color:green;font-weight:700}.cm-s-ipython span.cm-atom{color:#88F}.cm-s-ipython span.cm-number{80}.cm-s-ipython span.cm-def{f}.cm-s-ipython span.cm-variable{}.cm-s-ipython span.cm-operator{color:#A2F;font-weight:700}.cm-s-ipython span.cm-variable-2{color:#1a1a1a}.cm-s-ipython span.cm-variable-3{color:#333}.cm-s-ipython span.cm-comment{color:#408080;font-style:italic}.cm-s-ipython span.cm-string{color:#BA2121}.cm-s-ipython span.cm-string-2{color:#f50}.cm-s-ipython span.cm-meta{color:#A2F}.cm-s-ipython span.cm-qualifier{color:#555}.cm-s-ipython span.cm-builtin{color:green}.cm-s-ipython span.cm-bracket{color:#997}.cm-s-ipython span.cm-tag{color:#170}.cm-s-ipython span.cm-attribute{c}.cm-s-ipython span.cm-header{f}.cm-s-ipython span.cm-quote{90}.cm-s-ipython span.cm-link{c}.cm-s-ipython span.cm-error{color:red}.cm-s-ipython span.cm-tab{background:url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=')right no-repeat}div.output_wrapper{display:-webkit-box;-webkit-box-align:stretch;display:-moz-box;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch;z-index:1}div.output_scroll{height:24em;width:100%;overflow:auto;border-radius:2px;-webkit-box-shadow:inset 0 2px 8px rgba(0,0,0,.8);box-shadow:inset 0 2px 8px rgba(0,0,0,.8);display:block}div.output_collapsed{margin:0;padding:0;display:-webkit-box;-webkit-box-orient:vertical;display:-moz-box;-moz-box-orient:vertical;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}div.out_prompt_overlay{height:100%;padding:0 .4em;position:absolute;border-radius:2px}div.out_prompt_overlay:hover{-webkit-box-shadow:inset 0 0 1px #000;box-shadow:inset 0 0 1px #000;background:rgba(240,240,240,.5)}div.output_prompt{color:#8b0000}div.output_area{padding:0;page-break-inside:avoid;display:-webkit-box;-webkit-box-orient:horizontal;display:-moz-box;-moz-box-orient:horizontal;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}div.output_area .MathJax_Display{text-align:left!important}div.output_area div.output_area img,div.output_area svg{max-width:100%;height:auto}div.output_area img.unconfined,div.output_area svg.unconfined{max-width:none}.output{display:-webkit-box;-webkit-box-orient:vertical;display:-moz-box;-moz-box-orient:vertical;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}@media (max-width:540px){div.output_area{-webkit-box-orient:vertical;-moz-box-orient:vertical;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}}div.output_area pre{margin:0;padding:0;border:0;vertical-align:baseline;background-color:transparent;border-radius:0}div.output_subarea{overflow-x:auto;padding:.4em;-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1;max-width:calc(100% - 14ex)}div.output_text{text-align:left;line-height:1.21429em}div.output_stderr{background:#fdd}div.output_latex{text-align:left}div.output_javascript:empty{padding:0}.js-error{color:#8b0000}div.raw_input_container{font-family:monospace;padding-top:5px}span.raw_input_prompt{}input.raw_input{font-family:inherit;font-size:inherit;color:inherit;width:auto;vertical-align:baseline;padding:0 .25em;margin:0 .25em}input.raw_input:focus{box-shadow:none}p.p-space{margin-bottom:10px}div.output_unrecognized{padding:5px;font-weight:700;color:red}div.output_unrecognized a,div.output_unrecognized a:hover{color:inherit;text-decoration:none}.rendered_html{}.rendered_html :link,.rendered_html :visited,.rendered_html h1:first-child{margin-top:.538em}.rendered_html h2:first-child{margin-top:.636em}.rendered_html h3:first-child{margin-top:.777em}.rendered_html h4:first-child,.rendered_html h5:first-child,.rendered_html h6:first-child{margin-top:1em}.rendered_html *+ol,.rendered_html *+ul{margin-top:1em}.rendered_html *+table{margin-top:1em}.rendered_html *+p{margin-top:1em}.rendered_html *+img{margin-top:1em}div.text_cell{display:-webkit-box;-webkit-box-orient:horizontal;display:-moz-box;-moz-box-orient:horizontal;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}@media (max-width:540px){div.text_cell>div.prompt{display:none}}div.text_cell_render{outline:0;resize:none;width:inherit;border-style:none;padding:.5em .5em .5em .4em;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box}a.anchor-link:link{text-decoration:none;padding:0 20px;visibility:hidden}h1:hover .anchor-link,h2:hover .anchor-link,h3:hover .anchor-link,h4:hover .anchor-link,h5:hover .anchor-link,h6:hover .anchor-link{visibility:visible}.text_cell.rendered .input_area{display:none}.text_cell.rendered .text_cell.unrendered .text_cell_render{display:none}.cm-header-1,.cm-header-2,.cm-header-3,.cm-header-4,.cm-header-5,.cm-header-6{font-weight:700;font-family:\"Helvetica Neue\",Helvetica,Arial,sans-serif}.cm-header-1{font-size:185.7%}.cm-header-2{font-size:157.1%}.cm-header-3{font-size:128.6%}.cm-header-4{font-size:110%}.cm-header-5,.cm-header-6{font-size:100%;font-style:italic} .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ In [3]: % matplotlib inline import matplotlib.pyplot as plt import numpy as np import networkx as nx In [146]: import random from itertools import combinations edges = [] for ( u , v ) in combinations ( range ( 10 ), 2 ): r = random . random () if r < 0.5 : edges . append (( u , v )) for ( u , v ) in combinations ( range ( 8 ), 2 ): r = random . random () if r < 0.5 : edges . append (( u + 10 , v + 10 )) for ( u , v ) in combinations ( range ( 9 ), 2 ): r = random . random () if r < 0.6 : edges . append (( u + 18 , v + 18 )) for ( u , v ) in combinations ( range ( 5 ), 2 ): r = random . random () if r < 0.4 : edges . append (( u + 27 , v + 27 )) for ( u , v ) in combinations ( range ( 6 ), 2 ): r = random . random () if r < 0.1 : edges . append (( u , v + 10 )) for ( u , v ) in combinations ( range ( 7 ), 2 ): r = random . random () if r < 0.3 : edges . append (( u , v + 18 )) for ( u , v ) in combinations ( range ( 6 ), 2 ): r = random . random () if r < 0.2 : edges . append (( u , v + 27 )) print len ( edges ) test = nx . Graph () test . add_edges_from ( edges ) 76 [(0, 1), (0, 3), (0, 6), (0, 7), (0, 8), (0, 28), (1, 32), (1, 2), (1, 3), (1, 4), (1, 8), (1, 9), (1, 24), (2, 3), (2, 4), (2, 5), (2, 7), (2, 14), (2, 22), (2, 31), (3, 32), (3, 8), (3, 23), (3, 24), (4, 5), (4, 6), (4, 8), (4, 9), (4, 23), (5, 9), (7, 9), (8, 9), (10, 16), (10, 17), (10, 13), (10, 15), (11, 16), (11, 12), (11, 14), (11, 15), (12, 17), (12, 14), (14, 16), (15, 17), (16, 17), (18, 25), (18, 19), (18, 21), (18, 22), (19, 21), (19, 22), (19, 24), (19, 25), (19, 26), (20, 24), (20, 25), (20, 21), (20, 22), (20, 23), (21, 23), (21, 24), (21, 25), (21, 26), (22, 24), (22, 25), (23, 25), (24, 25), (24, 26), (25, 26), (27, 29), (27, 31), (28, 29), (28, 30), (29, 30), (29, 31), (30, 31)] In [148]: fp = file ( 'dataset' + str ( len ( test )) + '.txt' , 'w' ) for ( u , v ) in edges : fp . write ( ' %d %d \\n ' % ( u , v )) fp . close () In [206]: nx . draw ( test , with_label = True ) In [231]: pos = nx . spring_layout ( test ) nx . draw_networkx ( test , pos = pos ) In [5]: added = {} In [65]: def initializeCommunities ( g , k , S ): for v in g . nodes (): neighbors = g . neighbors ( v ) if len ( neighbors ) >= k : S [ v ] = set ( neighbors ) S [ v ] . add ( v ) added [ v ] = set ( neighbors ) #S.add(v) In [118]: def zeta ( v , S , g , k ): neighbors = set ( g . neighbors ( v )) . intersection ( S ) return 1.0 * ( len ( neighbors ) - k + 1 ) / ( len ( S ) - k ) if len ( neighbors ) > k else 0 def xi ( v , S , g ): neighbors = set ( g . neighbors ( v )) return 1.0 * len ( neighbors . intersection ( S )) / len ( neighbors ) def psi ( C , Cdot ): return 1.0 * len ( C . intersection ( Cdot )) / min ( len ( C ), len ( Cdot )) def findStayOff ( temp ): anchor = 0 mark = 0 for e in range ( len ( temp ) - 1 , 0 , - 1 ): if not mark and temp [ e ]: mark = temp [ e ] if temp [ e - 1 ] > temp [ e ] and temp [ e ] < mark : anchor = e break return anchor In [119]: temp = [ 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ] print findStayOff ( temp ) 7 In [8]: def computeScoreAndStayOff ( S , v , g , k ): count = max ( 20 , len ( g . neighbors ( v ))) ratio = 1.0 / count zeta_list = [ 0 ] * ( count + 1 ) data = {} score = zeta ( v , S [ s ], g , k ) if score > 0 : data [ s ] = score bucket = int ( score / ratio ) zeta_list [ bucket ] += 1 #if score > 0: # print score, len(set(g.neighbors(v)).intersection(S[s])), len(S[s]), bucket anchor = findStayOff ( zeta_list ) data [ 'cutoff' ] = ( anchor - 1 ) * ratio return data File \"<ipython-input-8-a2d52df34c17>\" , line 7 score = zeta(v, S[s], g, k) &#94; IndentationError : unexpected indent In [63]: def duplicationRemovel ( S , ovl ): delete_list = [] for ( s1 , s2 ) in combinations ( S . keys (), 2 ): if psi ( S [ s1 ], S [ s2 ]) > ovl and s1 not in delete_list and s2 not in delete_list : delete_list . append ( s2 ) print 'duplicate' , delete_list , len ( delete_list ) for e in delete_list : S . pop ( e ) return S In [124]: def selectBucket ( scores_list , count ): ratio = 1.0 / count bucket_list = [ 0 ] * ( count + 1 ) for e in scores_list : bucket = int ( e / ratio ) bucket_list [ bucket ] += 1 anchor = findStayOff ( bucket_list ) #print scores_list, bucket_list, anchor return anchor In [120]: print selectBucket ([ 0 , 1.0 ], 20 ) [0, 1.0] [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] 1 1 In [127]: def computeZetaList ( S , g , k ): zeta_scores = {} for i in S : for vj in S [ i ]: score = zeta ( vj , S [ i ], g , k ) if vj not in zeta_scores : zeta_scores [ vj ] = {} zeta_scores [ vj ][ i ] = score # for vj in zeta_scores: # print vj, zeta_scores[vj], g.neighbors(vj) return zeta_scores In [149]: S = {} initializeCommunities ( test , 2 , S ) S = duplicationRemovel ( S , 0.6 ) #for n in S: # print n, S[n] duplicate [6, 8, 32, 3, 4, 5, 7, 9, 15, 17, 12, 14, 19, 21, 22, 24, 25, 23, 29, 30, 31] 21 In [150]: zeta_scores = computeZetaList ( S , test , 2 ) for v in zeta_scores : count = max ( 20 , len ( test . neighbors ( v ))) anchor = selectBucket ( zeta_scores [ v ] . values (), count ) print v , zeta_scores [ v ], anchor zeta_scores [ v ][ 'cutoff' ] = anchor * 1.0 / count 0 {0: 1.0, 1: 0.2857142857142857, 28: 0} 6 1 {0: 0.4, 1: 1.0, 2: 0.2857142857142857} 9 2 {1: 0.2857142857142857, 2: 1.0} 6 3 {0: 0.4, 1: 0.7142857142857143, 2: 0} 9 4 {1: 0.42857142857142855, 2: 0.2857142857142857} 6 5 {2: 0} 0 6 {0: 0} 0 7 {0: 0, 2: 0} 0 8 {0: 0.4, 1: 0.5714285714285714} 9 9 {1: 0.2857142857142857} 0 10 {16: 0, 10: 1.0} 1 11 {16: 0, 11: 1.0} 1 12 {11: 0} 0 13 {10: 0} 0 14 {16: 0, 2: 0, 11: 0.6666666666666666} 1 15 {10: 0, 11: 0} 0 16 {16: 1.0, 10: 0, 11: 0} 1 17 {16: 0, 10: 0.6666666666666666} 1 18 {18: 1.0} 0 19 {18: 1.0, 26: 1.0} 0 20 {20: 1.0} 0 21 {18: 0.6666666666666666, 20: 0.75, 26: 1.0} 16 22 {2: 0, 20: 0.5, 18: 0.6666666666666666} 11 23 {20: 0.5} 0 24 {1: 0, 26: 1.0, 20: 0.75} 16 25 {18: 1.0, 20: 1.0, 26: 1.0} 0 26 {26: 1.0} 0 27 {27: 0} 0 28 {0: 0, 28: 1.0} 1 29 {27: 0, 28: 0} 0 30 {28: 0} 0 31 {2: 0, 27: 0} 0 32 {1: 0} 0 In [193]: def leaveCommunities ( S , g , k , ovl ): S = duplicationRemovel ( S , ovl ) zeta_scores = computeZetaList ( S , g , k ) for v in zeta_scores : count = max ( 20 , len ( g . neighbors ( v ))) anchor = selectBucket ( zeta_scores [ v ] . values (), count ) zeta_scores [ v ][ 'cutoff' ] = ( anchor - 1 ) * 1.0 / count delete_list = [] leave = 1 for s in S : for n in added [ s ]: if n not in S [ s ]: continue if n == s : continue if ( n not in zeta_scores or s not in zeta_scores [ n ]) and n in S [ s ]: S [ s ] . remove ( n ) if zeta_scores [ n ][ s ] < zeta_scores [ n ][ 'cutoff' ] or zeta_scores [ n ][ 'cutoff' ] == 0 : S [ s ] . remove ( n ) #print stay_cut_set[n][s] if len ( S [ s ]) < k : delete_list . append ( s ) leave = 0 for e in delete_list : S . pop ( e ) print 'after leave is: ' for e in S : print e , S [ e ] return leave In [197]: def expandCommunities ( S , g ): join_scores = {} for j in g . nodes (): if j not in join_scores : join_scores [ j ] = {} for i in S : score = xi ( j , S [ i ], g ) join_scores [ j ][ i ] = score for v in join_scores : count = max ( 20 , len ( g . neighbors ( v ))) anchor = selectBucket ( join_scores [ v ] . values (), count ) join_scores [ v ][ 'cutoff' ] = ( anchor - 1 ) * 1.0 / count #for e in join_scores: # print e, join_scores[e] #for e in added: # print e, added[e] nowadded = {} for i in S : nowadded [ i ] = set () for vj in added [ i ]: for uk in g . neighbors ( vj ): if uk not in join_scores or i not in join_scores [ uk ]: #print 'not in' , uk, i, uk not in join_scores, i not in join_scores[uk] continue if join_scores [ uk ][ i ] > join_scores [ uk ][ 'cutoff' ] and uk not in S [ i ]: S [ i ] . add ( uk ) nowadded [ i ] . add ( uk ) added [ i ] = nowadded [ i ] print 'after expand is: ' for e in S : print e , S [ e ] In [189]: t = {} #for e in added: # print e, added[e] initializeCommunities ( test , 2 , t ) leaveCommunities ( t , test , 2 , 0.6 ) #for e in added: # print e, added[e] S = { 0 : set ([ 0 , 1 , 3 , 6 , 7 , 8 ]), 1 : set ([ 0 , 32 , 2 , 3 , 4 , 1 , 8 , 9 ]), 2 : set ([ 2 , 4 , 5 , 7 , 31 ]), 10 : set ([ 10 , 13 , 15 ]), 11 : set ([ 11 , 12 , 15 ]), 18 : set ([ 25 , 18 , 19 , 22 ]), 20 : set ([ 20 , 21 , 22 , 23 , 24 , 25 ]), 26 : set ([ 24 , 25 , 26 , 19 , 21 ]), 27 : set ([ 27 , 29 , 31 ]), 28 : set ([ 28 , 29 , 30 ])} expandCommunities ( S , test ) for e in S : print e , S [ e ] duplicate [6, 8, 32, 3, 4, 5, 7, 9, 15, 17, 12, 14, 19, 21, 22, 24, 25, 23, 29, 30, 31] 21 after leave is: {0: set([0, 1, 3, 6, 7, 8]), 1: set([0, 32, 2, 3, 4, 1, 8, 9]), 2: set([2, 4, 5, 7, 31]), 10: set([10, 13, 15]), 11: set([11, 12, 15]), 18: set([25, 18, 19, 22]), 20: set([20, 21, 22, 23, 24, 25]), 26: set([24, 25, 26, 19, 21]), 27: set([27, 29, 31]), 28: set([28, 29, 30])} expand phrase 0 set([0, 1, 2, 3, 32, 6, 7, 8, 9, 4]) 1 set([0, 32, 2, 3, 4, 5, 6, 1, 8, 9, 7, 22, 28]) 2 set([2, 4, 5, 7, 9, 30, 31]) 27 set([27, 28, 29, 30, 31]) 20 set([18, 19, 20, 21, 22, 23, 24, 25]) 26 set([18, 19, 20, 21, 22, 24, 25, 26]) 10 set([16, 17, 10, 13, 15]) 11 set([11, 12, 14, 15, 16, 17]) 28 set([28, 29, 30, 31]) 18 set([18, 19, 21, 22, 24, 25]) In [203]: def preferredCommunities ( g , k , ovl ): S = {} initializeCommunities ( g , k , S ) print len ( S ) expand = 6 while expand : if expand <= 0 : break expand -= 1 leave = 1 leave = leaveCommunities ( S , g , k , ovl ) expandCommunities ( S , g ) print len ( S ) return S In [204]: z = preferredCommunities ( test , 2 , 0.6 ) print z . keys () 32 duplicate [6, 8, 32, 3, 4, 5, 7, 9, 15, 17, 12, 14, 19, 21, 22, 24, 25, 23, 29, 30, 31] 21 after leave is: 0 set([0, 1, 3, 6, 7, 8]) 1 set([0, 32, 2, 3, 4, 1, 8, 9]) 2 set([2, 4, 5, 7, 31]) 10 set([10, 13, 15]) 11 set([11, 12, 15]) 18 set([25, 18, 19, 22]) 20 set([20, 21, 22, 23, 24, 25]) 26 set([24, 25, 26, 19, 21]) 27 set([27, 29, 31]) 28 set([28, 29, 30]) after expand is: 0 set([0, 1, 2, 3, 32, 6, 7, 8, 9, 4]) 1 set([0, 32, 2, 3, 4, 5, 6, 1, 8, 9, 7, 22, 28]) 2 set([2, 4, 5, 7, 9, 30, 31]) 10 set([16, 17, 10, 13, 15]) 11 set([11, 12, 14, 15, 16, 17]) 18 set([18, 19, 21, 22, 24, 25]) 20 set([18, 19, 20, 21, 22, 23, 24, 25]) 26 set([18, 19, 20, 21, 22, 24, 25, 26]) 27 set([27, 28, 29, 30, 31]) 28 set([28, 29, 30, 31]) duplicate [1, 20, 26, 28] 4 after leave is: 0 set([0, 1, 2, 3, 32, 6, 7, 8, 9, 4]) 2 set([2, 4, 5, 7, 9, 31]) 10 set([17, 10, 13, 15]) 11 set([11, 12, 14, 15, 17]) 18 set([18, 19, 21, 22, 24, 25]) 27 set([27, 28, 29, 31]) after expand is: 0 set([0, 1, 2, 3, 32, 5, 6, 7, 8, 9, 22, 23, 4]) 2 set([1, 2, 4, 5, 7, 9, 31]) 10 set([10, 12, 13, 15, 17]) 11 set([2, 11, 12, 14, 15, 16, 17]) 18 set([3, 18, 19, 20, 21, 22, 23, 24, 25, 26]) 27 set([0, 27, 28, 29, 30, 31]) duplicate [2] 1 after leave is: 0 set([0, 1, 2, 3, 32, 5, 6, 7, 8, 9, 4]) 10 set([10, 13, 15, 17]) 11 set([11, 12, 14, 15, 16, 17]) 18 set([18, 19, 20, 21, 22, 24, 25, 26]) 27 set([27, 28, 29, 30, 31]) after expand is: 0 set([0, 1, 2, 3, 32, 5, 6, 7, 8, 9, 4]) 10 set([10, 13, 15, 17]) 11 set([10, 11, 12, 14, 15, 16, 17]) 18 set([1, 2, 3, 18, 19, 20, 21, 22, 23, 24, 25, 26]) 27 set([27, 28, 29, 30, 31]) duplicate [11] 1 after leave is: 0 set([0, 1, 2, 3, 32, 5, 6, 7, 8, 9, 4]) 10 set([10, 13, 15, 17]) 18 set([1, 2, 3, 18, 19, 20, 21, 22, 23, 24, 25, 26]) 27 set([27, 28, 29, 30, 31]) after expand is: 0 set([0, 1, 2, 3, 32, 5, 6, 7, 8, 9, 4]) 10 set([10, 13, 15, 17]) 18 set([0, 1, 2, 3, 4, 5, 32, 7, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26]) 27 set([27, 28, 29, 30, 31]) duplicate [18] 1 after leave is: 0 set([0, 1, 2, 3, 32, 5, 6, 7, 8, 9, 4]) 10 set([10, 13, 15, 17]) 27 set([27, 28, 29, 30, 31]) after expand is: 0 set([0, 1, 2, 3, 32, 5, 6, 7, 8, 9, 4]) 10 set([10, 13, 15, 17]) 27 set([27, 28, 29, 30, 31]) duplicate [] 0 after leave is: 0 set([0, 1, 2, 3, 32, 5, 6, 7, 8, 9, 4]) 10 set([10, 13, 15, 17]) 27 set([27, 28, 29, 30, 31]) after expand is: 0 set([0, 1, 2, 3, 32, 5, 6, 7, 8, 9, 4]) 10 set([10, 13, 15, 17]) 27 set([27, 28, 29, 30, 31]) 3 [0, 10, 27] In [214]: print z {0: set([0, 1, 2, 3, 32, 5, 6, 7, 8, 9, 4]), 10: set([10, 13, 15, 17]), 27: set([27, 28, 29, 30, 31])} In [217]: colors = [ 'r' ] * len ( test . nodes ()) cmap = { 0 : 'b' , 10 : 'yellow' , 27 : 'g' } for e in z : for n in z [ e ]: colors [ n ] = cmap [ e ] print colors [&apos;b&apos;, &apos;b&apos;, &apos;b&apos;, &apos;b&apos;, &apos;b&apos;, &apos;b&apos;, &apos;b&apos;, &apos;b&apos;, &apos;b&apos;, &apos;b&apos;, &apos;yellow&apos;, &apos;r&apos;, &apos;r&apos;, &apos;yellow&apos;, &apos;r&apos;, &apos;yellow&apos;, &apos;r&apos;, &apos;yellow&apos;, &apos;r&apos;, &apos;r&apos;, &apos;r&apos;, &apos;r&apos;, &apos;r&apos;, &apos;r&apos;, &apos;r&apos;, &apos;r&apos;, &apos;r&apos;, &apos;g&apos;, &apos;g&apos;, &apos;g&apos;, &apos;g&apos;, &apos;g&apos;, &apos;b&apos;] In [238]: nx . draw_networkx ( test , node_size = 150 , node_color = colors ) In [ ]: data = np . loadtxt ( '../dataset/com-dblp.ungraph.txt' , dtype = np . int32 , delimiter = ' \\t ' ) In [52]: G = nx . Graph () G . add_edges_from ( data ) g = nx . adjacency_matrix ( G ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-52-22ddee6160e7> in <module> () 2 3 G = nx . Graph ( ) ----> 4 G . add_edges_from ( data ) 5 g = nx . adjacency_matrix ( G ) NameError : name &apos;data&apos; is not defined if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); } if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"研究","title":"FOCS总结"},{"url":"sndnyang.github.io/d3js_learn_1.html","text":"流程 一、添加 svg 画布， 得到一个 选择器selection var svg = d3.select(\"body\") //选择文档中的某一元素，根据CSS规范，如 \"body\" .append(\"svg\") //添加一个svg元素, 符合html操作 .attr(\"width\", width) //设定宽度 .attr(\"height\", height); //设定高度 二、布局（转换数据） 2.1 种类 布局种类 2.2 定义布局 var mylayout = d3.layout.tree() // 例： Tree布局 2.3 设置布局的基本属性（接上一项） .size ([ width , height ]) // tree 只想到这个属性 2.4 用布局转换数据 var nodes = mylayout.nodes(data)[.reverse()] // reverse 逆序， data格式有讲究， json且属性名字限定 var links = mylayout.links(nodes) // 树图要生成点和边 或者 var piedata = pie(dataset); // 饼状图就不需要边了 三、数据绑定到元素（默认新建元素） 3.1 从画布选择器中，再选择后代元素 svg.select(name) // 选择第一个匹配的元素 或者 svg.selectAll(name) // 选择全部匹配的元素 3.2 加载数据（接上一项） .data ( dataset ) // 元素和数据集一对一加载 , 此时得到的叫 update 部分 或者 .datum ( oneData ) // 一个数据绑定给全部元素 3.3 对应数据来创建元素（接上一项），如果元素是现成的不需要建 .enter () // 只能接上一项 数据加载 , 此时得到的叫 enter 部分 .append ( type ) // 创建需要类型的元素 3.4 数据属性设置（例） 根据上一项的 type 和 数据， 设置需要的属性 .attr ( \"x\" , 20 ) //屏幕上的起始横坐标 .attr ( \"y\" , function ( d , i ) { //屏幕上的起始纵坐标 return i * rectHeight ; }) .attr ( \"width\" , function ( d ) { // 元素宽度（有这个属性的话） return d ; }) .attr ( \"height\" , rectHeight-2 ) // 元素高度（有这个属性的话） .attr ( \"fill\" , \"steelblue\" ) ; // 颜色填充 3.5 事件设置（也是属性） .on ( \"mouseover\" , function ( d , i ) {} ) .on ( \"mouseout\" , function ( d , i ) {} ) .on ( \"click\" , function ( d , i ) {} ) 在该元素下继续添加其他子元素 前面3.1-3.5步骤结果保存在某变量中， 即可使用该变量继续append,设置属性和事件 四、动画效果 4.1 方法 transition() // 启动过渡效果, 其前后是图形变化前后的状态（形状、位置、颜色等等） duration() // 指定过渡的持续时间，单位为毫秒 ease() 指定过渡的方式，常用的有： linear：普通的线性变化 circle：慢慢地到达变换的最终状态 elastic：带有弹跳的到达最终状态 bounce：在最终状态处弹跳几次 delay() 指定延迟的时间，可用匿名函数function(d,i) 指定各个的延迟 4.2 创建动态效果 var transition = selection.transition() .duration(time) .attr()... // 定义变量是可能用于4.3 4.3 对子元素进行处理 如果元素中有子元素，需要一并处理。 transition.select(name).attr()","tags":"工具","title":"D3.js 学习心得一"},{"url":"sndnyang.github.io/memory-movies-week1.html","text":"记忆概念 分类 working memory episodic memory semantic memory procedural memory working memory workbench(工作台) -- 维持、操作思维和意识 特点：短暂","tags":"心理学","title":"记忆与电影-第一周"},{"url":"sndnyang.github.io/word2vec-2-mindmap.html","text":"译自： 原文链接 (没有找过作者， 随手就翻译了) 思维导图这一工具因其长于组织大量任务、材料信息，在头脑风暴、 计划和问题解决等领域得到广泛使用、一致好评。 对思路的可视整理有助于整个思考的过程， 并且模拟了我们人类思考时获取脑中知识的方式。 现今有很多工具可以帮助我们画出思维导图， 但还没有一个能自行生成的， \"生成\"是指从文本（语音）内容中提成。 为了做到这一点， 我花了最长的时间（至今快8个月了）， 研究如何结合文本挖掘和图论做成一个框架来生成思维导图（给定一段文本）。 当然， 第一个问题就是， 任意一段文字都不会只有那么一种可行的思维导图。 只是， 如果你要构建自己的思维导图， 有这么一个自动工具， 可能会给你更多的思路和洞见， 特别是头脑风暴时， 或帮你查缺补漏。 那我们先来看看一个思维导图的样式—— 两个关键点： 思维导图并不简单地是一棵树， 不只是递归地将主题划分成子主题。 它本质上更像图， 连接项在语义上是相关的。 正如‘夜晚'可能会让你想到‘白天'， 思维导图中， 意义相反的两个概念之间也很可能存在连接。 还有诸如使用图片强化概念等其他点。但这些并不是本文的主旨（我的设计师风格创造力糟透了）。 有备无患 ， Heres 这篇文章能帮助你熟悉构建和使用思维导图的过程。 在我上一篇博文 链接 中， 我描述了一种从文本生成Word2Vec模型的方法（使用维基的文章作为示例）。 在这里， 我将描述我使用的从 Word2Vec模型生成基本思维导图的方法。 第一步： 从文章中找出前n项 （就像我上一篇博文所说， 我只使用stemmed unigrams（一个词干的n-gram), 你可以自行采用更高阶的ngrams, 想来会更棘手（准确来说， 是当你生成n-gram的算法有效时） 这里的 n 是指思维导图中的节点数， 在我多次尝试之后， 50是个比较好的数字， 太小则信息少， 太大则噪音多。 欢迎尝试其他数字。 我使用了本文 链接 中写的 co-occurrence 方法， 列出文本的前 n 项词。 代码如下： def _get_param_matrices(vocabulary, sentence_terms): \"\"\" Returns ======= 1. Top 300(or lesser, if vocab is short) most frequent terms(list) 2. co-occurence matrix wrt the most frequent terms(dict) 3. Dict containing Pg of most-frequent terms(dict) 4. nw(no of terms affected) of each term(dict) \"\"\" #Figure out top n terms with respect to mere occurences n = min(300, len(vocabulary)) topterms = list(vocabulary.keys()) topterms.sort(key = lambda x: vocabulary[x], reverse = True) topterms = topterms[:n] #nw maps term to the number of terms it 'affects' #(sum of number of terms in all sentences it #appears in) nw = {} #Co-occurence values are wrt top terms only co_occur = {} #Initially, co-occurence matrix is empty for x in vocabulary: co_occur[x] = [0 for i in range(len(topterms))] #Iterate over list of all sentences' vocabulary dictionaries #Build the co-occurence matrix for sentence in sentence_terms: total_terms = sum(list(sentence.values())) #This list contains the indices of all terms from topterms, #that are present in this sentence top_indices = [] #Populate top_indices top_indices = [topterms.index(x) for x in sentence if x in topterms] #Update nw dict, and co-occurence matrix for term in sentence: nw[term] = nw.get(term, 0) + total_terms for index in top_indices: co_occur[term][index] += (sentence[term] * sentence[topterms[index]]) #Pg is just nw[term]/total vocabulary of text Pg = {} N = sum(list(vocabulary.values())) for x in topterms: Pg[x] = float(nw[x])/N return topterms, co_occur, Pg, nw def get_top_n_terms(vocabulary, sentence_terms, n=50): \"\"\" Returns the top 'n' terms from a block of text, in the form of a list, from most important to least. 'vocabulary' should be a dict mapping each term to the number of its occurences in the entire text. 'sentence_terms' should be an iterable of dicts, each denoting the vocabulary of the corresponding sentence. \"\"\" #First compute the matrices topterms, co_occur, Pg, nw = _get_param_matrices(vocabulary, sentence_terms) #This dict will map each term to its weightage with respect to the #document result = {} N = sum(list(vocabulary.values())) #Iterates over all terms in vocabulary for term in co_occur: term = str(term) org_term = str(term) for x in Pg: #expected_cooccur is the expected cooccurence of term with this #term, based on nw value of this and Pg value of the other expected_cooccur = nw[term] * Pg[x] #Result measures the difference(in no of terms) of expected #cooccurence and actual cooccurence result[org_term] = ((co_occur[term][topterms.index(x)] - expected_cooccur)**2/ float(expected_cooccur)) terms = list(result.keys()) terms.sort(key=lambda x: result[x], reverse=True) return terms[:n] get_top_n_terms 函数实现了这个功能， 我希望我写的 docstring 和 注释很好地解释了整个过程（结合起那篇论文）。 如果你有时间， 足够耐心， 你可以看到你Word2Vec模型里的整个词库（entire vocabulary）， 并找到你想加入到你的思维导图里的那些项。 这样做大概能得到最好的结果（就是太辛苦）。 第二步： 选定根节点 根结点是最能表达思维导图中心思想的。 相比起整个词库entire vocabulary， 选中的结点个数小上许多， 所以， 也许最好就是 手工选定根结点的项。 或者， 使用出现频率最高的（has the highest occurrence）。这一步也需要很多尝试（但数学科学能起什么作用吗） 第三步： 生成导图 这是至关重要的一步， 也是我花了最多时间的。 首先， 我需要定义一个项（term）的 情境向量（contextual vector） 假设， 本导图的根是‘电脑'， 连到另一个项‘硬件'， ‘硬件'再连‘键盘'， 那么， ‘键盘'的Word2Vec向量以 model[keyboard]的方式在Python/Gensim中获得。 定义这个向量为 $ v_{keyboard} $ 现在考虑构建过程。 因为你目前已经有了一些东西， 你再想到'键盘' 时， 其实已经处于'电脑'和 '硬件' 的情境（上下文）中。 所以你很难把 '键盘‘ 跟 '音乐‘ 联系起来（最起码不直接相关）。 可见， '键盘' 的contextual vector情境向量（定义为 $ v&#94;{'}_{keyboard} $ ) 一定会将方向偏向到 $ v 和 v_{hardware} $ (be biased in its direction towards). ---- 我们要计算 Word2Vec 模型的 cosine 相似度， 当然只跟方向有关。 从直觉上说， $ v_{hardware} 和 v&#94;{'}_{keyboard} $ 的影响应该大于的影响应该大于 v ， 也就是距离越远， 父节点的影响会越小。 为了考虑这个因素， 我再加入了一个 参数 情境递减因子 αα 。 数学表达如下： $$ v&#94;{'}_{computer} = v v&#94;{'} {hardware} = (1-\\alpha)v + \\alpha v&#94;{'} v&#94;{'} = (1-\\alpha)v_{keyboard} + \\alpha v&#94;{'}_{hardware} $$ 最后， 可以生成实际的导图了， 以下是我使用的算法（我希望行内注释能帮你理解我的工作） from scipy.spatial.distance import cosine from networkx import Graph def build_mind_map ( model , stemmer , root , nodes , alpha = 0.2 ): \"\"\" Returns the Mind-Map in the form of a NetworkX Graph instance. 'model' should be an instance of gensim.models.Word2Vec 'nodes' should be a list of terms, included in the vocabulary of 'model'. 'root' should be the node that is to be used as the root of the Mind Map graph. 'stemmer' should be an instance of StemmingHelper. \"\"\" #This will be the Mind-Map g = Graph () #Ensure that the every node is in the vocabulary of the Word2Vec #model, and that the root itself is included in the given nodes for node in nodes : if node not in model . vocab : raise ValueError ( node + \" not in model's vocabulary\" ) if root not in nodes : raise ValueError ( \"root not in nodes\" ) ##Containers for algorithm run #Initially, all nodes are unvisited unvisited_nodes = set ( nodes ) #Initially, no nodes are visited visited_nodes = set ([]) #The following will map visited node to its contextual vector visited_node_vectors = {} #Thw following will map unvisited nodes to (closest_distance, parent) #parent will obviously be a visited node node_distances = {} #Initialization with respect to root current_node = root visited_node_vectors [ root ] = model [ root ] unvisited_nodes . remove ( root ) visited_nodes . add ( root ) #Build the Mind-Map in n-1 iterations for i in range ( 1 , len ( nodes )): #For every unvisited node 'x' for x in unvisited_nodes : #Compute contextual distance between current node and x dist_from_current = cosine ( visited_node_vectors [ current_node ], model [ x ]) #Get the least contextual distance to x found until now distance = node_distances . get ( x , ( 100 , '' )) #If current node provides a shorter path to x, update x's #distance and parent information if distance [ 0 ] > dist_from_current : node_distances [ x ] = ( dist_from_current , current_node ) #Choose next 'current' as that unvisited node, which has the #lowest contextual distance from any of the visited nodes next_node = min ( unvisited_nodes , key = lambda x : node_distances [ x ][ 0 ]) ##Update all containers parent = node_distances [ next_node ][ 1 ] del node_distances [ next_node ] next_node_vect = (( 1 - alpha ) * model [ next_node ] + alpha * visited_node_vectors [ parent ]) visited_node_vectors [ next_node ] = next_node_vect unvisited_nodes . remove ( next_node ) visited_nodes . add ( next_node ) #Add the link between newly selected node and its parent(from the #visited nodes) to the NetworkX Graph instance g . add_edge ( stemmer . original_form ( parent ) . capitalize (), stemmer . original_form ( next_node ) . capitalize ()) #The new node becomes the current node for the next iteration current_node = next_node return g 备注： 我使用了 NetworkX 的简易图构建架构来完成了思维导图生成的核心任务（使之更易用于可视化）。 要计算 余弦距离， 我使用了 SciPy. 另外注意74和75行， 我使用了上篇博文所写的 StemmingHelper 类， 所以在思维导图中显示的是词干原始形式， 而不是词干。可以将StemmingHelper类直接当做参数 stemmer 传入。 所以， 如果你不需要词干处理， 那就把第4,74,75三行的代码干掉吧。 如果你仔细看过代码， 你会发现， 这看着很像 迪杰斯特拉的单点最短路径， 只是情境不同。 示例输出 原文链接 自己看。 看着不错， 和我人工画的也挺像的。 其他 还有一些可尝试的东西。 比如加入 bi-grams 和 trigrams。 我相信能让 Word2Vec 模型更强大， 能对文本做出更好的释义。 导图中仍存在多余项， 但它给出了文本的（最？）短长度（相对其他文本挖掘任务来说）， 这种关键词提取算法（我在上文提到过的论文）似乎相当不错。 这段翻译有点不确认（There are some unnecessary terms in the Mind Maps, but given the short length of the texts (compared to most text mining tasks), the Keyword extraction algorithm in the paper I mentioned before, seems really good.） 此方法可用于头脑风暴， 从你选择的一点出发， 这代码框架会给出建议的可连项， 你再做出选择， 然后又可以得到新的推荐——就有点像思维导图助手。 无论怎样， 这都是篇长博文了， 谢谢你坚持着读完全文！（翻译也一样感谢您的阅读）。","tags":"翻译","title":"基于Word2Vec生成基本的思维导图"}]}