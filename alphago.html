<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="杨秀隆 X2015221018">
  <title>alpha 介绍</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="//cdn.bootcss.com/reveal.js/3.2.0/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="//cdn.bootcss.com/reveal.js/3.2.0/css/theme/black.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? '//cdn.bootcss.com/reveal.js/3.2.0/css/print/pdf.css' : '//cdn.bootcss.com/reveal.js/3.2.0/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="//cdn.bootcss.com/reveal.js/3.2.0/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
  <h1 class="title">alpha 介绍</h1>
  <h2 class="author">杨秀隆 X2015221018</h2>
  <h3 class="date">2016-3-25</h3>
</section>

<section><section id="导论" class="titleslide slide level1"><h1>导论</h1></section><section id="参考文献" class="slide level2">
<h1>参考文献</h1>
<ol type="1">
<li>原文:Mastering the Game of Go with Deep Neural Networks and Tree Search</li>
<li><a href="//mp.weixin.qq.com/s?__biz=MzIxNjE3MTM5OA==&amp;mid=402241411&amp;idx=1&amp;sn=98557fdc359a17af9ab6b1ed7e09854a&amp;scene=1&amp;srcid=0314rM6ivyxIaEMfKIaW167Z&amp;from=groupmessage&amp;isappinstalled=0#wechat_redirect">alphago-原理</a> 郑宇,张钧波</li>
<li><a href="//zhuanlan.zhihu.com/yuandong/20607684">alphago-分析</a> 田渊栋</li>
<li>how alphago work</li>
<li>开源代码 <a href="//github.com/Rochester-NRT/AlphaGo">alphago-code</a></li>
</ol>
</section><section id="战绩" class="slide level2">
<h1>战绩</h1>
<h4 id="对欧洲冠军-fan-hui">对欧洲冠军 Fan Hui</h4>
<figure>
<img src="img/fanhui.png" alt="fanhui" /><figcaption>fanhui</figcaption>
</figure>
<ol type="1">
<li>formal games were 1 hour main time plus 3 periods of 30 seconds byoyomi</li>
<li>informal games were 3 periods of 30 seconds byoyomi</li>
</ol>
</section><section class="slide level2">

<h3 id="对李世石">对李世石</h3>
<ol type="1">
<li>2016.3.9 alpha胜</li>
<li>2016.3.10 alpha胜</li>
<li>2016.3.12 alpha胜</li>
<li>2016.3.13 李世石胜</li>
<li>2016.3.15 alpha胜</li>
</ol>
</section></section>
<section><section id="基本定义" class="titleslide slide level1"><h1>基本定义</h1></section><section id="棋盘状态" class="slide level2">
<h1>棋盘状态</h1>
<figure>
<img src="img/go-state.png" alt="go-state" /><figcaption>go-state</figcaption>
</figure>
</section><section id="动作-action" class="slide level2">
<h1>动作 action</h1>
<p><strong>a</strong>: action 动作</p>
<figure>
<img src="img/go-action.png" alt="go-action" /><figcaption>go-action</figcaption>
</figure>
</section><section id="暴搜不可行" class="slide level2">
<h1>暴搜不可行！！！</h1>
<figure>
<img src="img/go-brute.png" alt="go-brute" /><figcaption>go-brute</figcaption>
</figure>
</section><section class="slide level2">

<h3 id="组合爆炸">组合爆炸！！！</h3>
<ol type="1">
<li>围棋的可能状态数大约在 250^150</li>
<li>国际象棋 35^80</li>
</ol>
</section><section id="策略" class="slide level2">
<h1>策略</h1>
<ol type="1">
<li>减少搜索树的深度， 即先行评估位置， 避免深度递归</li>
<li>减少搜索树的广度， 即减少可能动作分支</li>
</ol>
</section></section>
<section><section id="方法" class="titleslide slide level1"><h1>方法</h1></section><section id="section" class="slide level2">
<h1></h1>
<figure>
<img src="img/principle.jpg" alt="principle" /><figcaption>principle</figcaption>
</figure>
</section><section id="步骤" class="slide level2">
<h1>步骤</h1>
<ol type="1">
<li>用棋谱数据 训练 监督学习策略(走棋)网络, 同时训练快速走子策略</li>
<li>对策略网络进行强化学习， 程序自我对弈</li>
<li>训练一个价值网络， 预测胜率</li>
<li>用MCTS 结合策略网络和价值网络</li>
</ol>
</section><section id="组成" class="slide level2">
<h1>组成</h1>
<p>链接：//zhuanlan.zhihu.com/yuandong/20607684 来源：知乎</p>
<ol type="1">
<li>走棋网络（Policy Network），给定当前局面，预测/采样下一步的走棋。</li>
<li>快速走子（Fast rollout），目标和1一样，但在适当牺牲走棋质量的条件下，速度要比1快1000倍。</li>
<li>估值网络（Value Network），给定当前局面，估计是白胜还是黑胜。</li>
<li>蒙特卡罗树搜索（Monte Carlo Tree Search，MCTS)，把以上这三个部分连起来，形成一个完整的系统。</li>
</ol>
</section></section>
<section><section id="一.-策略网络学习" class="titleslide slide level1"><h1>一. 策略网络学习</h1></section><section id="监督学习" class="slide level2">
<h1>监督学习</h1>
<p>训练集数据： KGS 专业棋手(5-9段)的棋谱， 大概16万局棋， 3千万种棋盘状态</p>
<p>学习到一个预测模型 g</p>
<ol type="1">
<li>状态S</li>
<li>预测模型 g:S-&gt;p(a|S)</li>
<li>概率 p(a|S)</li>
<li>概率最大的动作 a</li>
</ol>
</section><section id="模型学习算法" class="slide level2">
<h1>模型学习算法</h1>
<p>深度学习： Convolutional Neural Network (CNN)， 卷积神经网络</p>
<ol type="1">
<li>围棋对局势的评估很难建模， 抽象</li>
<li>CNN正好擅长抽象</li>
</ol>
<p><a href="//scs.ryerson.ca/~aharley/vis/conv/">visual-cnn</a></p>
<p>另用线性模型训练快速策略</p>
</section><section class="slide level2">

<figure>
<img src="img/cnn.png" alt="cnn" /><figcaption>cnn</figcaption>
</figure>
</section><section id="预测" class="slide level2">
<h1>预测</h1>
<ol type="1">
<li>输入： 棋盘状态S</li>
<li>输出： 所有合法动作a 的概率分布</li>
</ol>
</section></section>
<section><section id="二.-策略网络强化" class="titleslide slide level1"><h1>二. 策略网络强化</h1></section><section id="对弈激励" class="slide level2">
<h1>对弈激励</h1>
<p>当前版本的策略网络 与 随机的一个版本</p>
<p>胜 z_t = +1, 负= -1, 未结束=0</p>
<figure>
<img src="img/go-rl.png" alt="go-rl" /><figcaption>go-rl</figcaption>
</figure>
</section></section>
<section><section id="三.-价值网络强化" class="titleslide slide level1"><h1>三. 价值网络强化</h1></section><section id="步骤-1" class="slide level2">
<h1>步骤</h1>
<p>输入状态S, 经过</p>
<ol type="1">
<li>监督策略网络 生成前 U-1步</li>
<li>随机采样 决定 第U步</li>
<li>增强策略网络 完成剩下博弈</li>
</ol>
<p>胜负作为输出</p>
</section><section id="训练过程" class="slide level2">
<h1>训练过程</h1>
<ol type="1">
<li>三千万局自我对弈</li>
<li>一局只有一个数据(sU+1, zU+1)</li>
<li>用神经网络进行回归学习</li>
</ol>
<p>学到价值网络， 判断该盘面的输赢概率</p>
</section><section class="slide level2">

<h3 id="reduce-搜索空间的方案">reduce 搜索空间的方案</h3>
<ol type="1">
<li>减少搜索树的深度， 价值网络 value network</li>
<li>减少搜索树的广度， 策略网络 policy network</li>
</ol>
</section></section>
<section><section id="四.-monte-carlo-树搜索" class="titleslide slide level1"><h1>四. monte-carlo 树搜索</h1></section><section id="monte-carlo" class="slide level2">
<h1>monte-carlo</h1>
<p>把随机算法分成两类：</p>
<ol type="1">
<li>蒙特卡罗算法：采样越多，越近似最优解；</li>
<li>拉斯维加斯算法：采样越多，越有机会找到最优解；</li>
</ol>
</section><section id="步骤-2" class="slide level2">
<h1>步骤</h1>
<p>当前盘面状态</p>
<ol type="1">
<li>选择， 用策略网络剪枝</li>
<li>扩展</li>
<li>评估， 使用价值网络</li>
<li>回溯</li>
</ol>
</section><section id="树的组成" class="slide level2">
<h1>树的组成</h1>
<p>对 每条边(状态s, 动作a)</p>
<ol type="1">
<li>动作值 action value Q(s, a)</li>
<li>访问次数 visit count N(s, a)</li>
<li>先验概率 prior probability P(s, a), 初始化为 策略网络值 p(a|s)</li>
</ol>
</section><section class="slide level2">

<h3 id="图示">图示：</h3>
<figure>
<img src="img/go-mcts2.png" alt="go-mcts" /><figcaption>go-mcts</figcaption>
</figure>
</section><section id="fast-rollout快速走子" class="slide level2">
<h1>Fast rollout快速走子</h1>
<p>局部特征匹配（local pattern matching）加线性回归（logistic regression)</p>
</section></section>
<section><section id="谢谢" class="titleslide slide level1"><h1>谢谢</h1></section></section>
    </div>
  </div>

  <script src="//cdn.bootcss.com/reveal.js/3.2.0/lib/js/head.min.js"></script>
  <script src="//cdn.bootcss.com/reveal.js/3.2.0/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // //github.com/hakimel/reveal.js#configuration
      Reveal.initialize({

        // Optional reveal.js plugins
        dependencies: [
          { src: '//cdn.bootcss.com/reveal.js/3.2.0/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: '//cdn.bootcss.com/reveal.js/3.2.0/plugin/zoom-js/zoom.js', async: true },
          { src: '//cdn.bootcss.com/reveal.js/3.2.0/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
